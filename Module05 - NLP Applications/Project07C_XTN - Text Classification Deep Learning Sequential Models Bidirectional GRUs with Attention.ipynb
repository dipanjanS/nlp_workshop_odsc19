{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module05%20-%20NLP%20Applications/Project07C_XTN%20-%20Text%20Classification%20Deep%20Learning%20Sequential%20Models%20Bidirectional%20GRUs%20with%20Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysuLv6mAGYRG"
   },
   "source": [
    "# Text Classification - Deep Learning Sequential Models - Bidirectional GRUs with Attention\n",
    "\n",
    "Bi-directional Models help us to capture better contextual information of sequences by going front to back and back to front of the same sequence and concatenating\\averaging the contextual information from the hidden states. Also instead of just passing in the last hidden state from the LSTM\\GRU we can push all the states to an attention model to attend to the most important words based on the cell states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "CV2VaftX3JO4",
    "outputId": "d8d486df-60a4-4832-b097-84413831aca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  6 01:45:33 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   71C    P8    17W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "Hw7MTNQvzCeG",
    "outputId": "d9dbe0c3-e7cd-4e23-af1b-f544c51b9e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.21)\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.1.1)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch\n",
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00XtRoYJzLCE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "EiYUcmc2zQzj",
    "outputId": "654a92e1-d98c-4c71-c6b9-0c6641a6de23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2', compression='bz2')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PxD5STf-zTS9",
    "outputId": "736966d0-33be-4330-a8c2-7a3356135095"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZXAHlptzXEJ"
   },
   "outputs": [],
   "source": [
    "# build train and test datasets\n",
    "reviews = dataset['review'].values\n",
    "sentiments = dataset['sentiment'].values\n",
    "\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdf34cuq0W6V"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  [s.extract() for s in soup(['iframe', 'script'])]\n",
    "  stripped_text = soup.get_text()\n",
    "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "  return stripped_text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "  norm_docs = []\n",
    "  for doc in tqdm.tqdm(docs):\n",
    "    doc = strip_html_tags(doc)\n",
    "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    doc = doc.lower()\n",
    "    doc = remove_accented_chars(doc)\n",
    "    doc = contractions.fix(doc)\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    doc = doc.strip()  \n",
    "    norm_docs.append(doc)\n",
    "  \n",
    "  return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-CRzsnGq0ZSK",
    "outputId": "ef9fb588-3954-4530-9269-59152b18f03d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35000/35000 [00:19<00:00, 1781.40it/s]\n",
      "100%|██████████| 15000/15000 [00:08<00:00, 1794.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 s, sys: 145 ms, total: 28 s\n",
      "Wall time: 28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "norm_train_reviews = pre_process_corpus(train_reviews)\n",
    "norm_test_reviews = pre_process_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYjVqlz10c2_"
   },
   "source": [
    "## Data Preprocessing and formatting\n",
    " \n",
    "To prepare text data for our deep learning model, we transform each review into a sequence.\n",
    "Every word in the review is mapped to an integer index and thus the sentence turns into a sequence of numbers.\n",
    "\n",
    "To perform this transformation, keras provides the ```Tokenizer```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xf_Ck9Hc0oPo",
    "outputId": "31db5853-61c4-4cc7-ef36-698eb18cbf5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "t = keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(norm_train_reviews)\n",
    "t.word_index['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jerA4iHk0qGF",
    "outputId": "fd85c53b-9f56-4d3f-8062-1e2180894bef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('dawgis', 175859), ('<PAD>', 0), 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtrRwXbI05Qr"
   },
   "outputs": [],
   "source": [
    "train_sequences = t.texts_to_sequences(norm_train_reviews)\n",
    "test_sequences = t.texts_to_sequences(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Invj0gRk0-RW",
    "outputId": "6b178f3c-e5a1-4748-9abc-e72596012170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=175860\n",
      "Number of Documents=35000\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "colab_type": "code",
    "id": "Fq8BhTsM1AX2",
    "outputId": "48f0a78b-1a1a-4086-8a02-ce7cfde6b6a9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAFpCAYAAABTU9T4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_lens = [len(s) for s in train_sequences]\n",
    "test_lens = [len(s) for s in test_sequences]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "h1 = ax[0].hist(train_lens)\n",
    "h2 = ax[1].hist(test_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5ZMlD241CVr"
   },
   "source": [
    "### Sequence Normalization\n",
    "\n",
    "Not all reviews are of same length. To handle this difference in length of reviews, we define a maximum length.\n",
    "For reviews which are smaller than this length, we pad them with zeros which longer ones are truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CaP_1s41GCL"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Op62mTZT1M4B",
    "outputId": "9d87e774-13c9-42e9-f307-0f9e57d07fd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 1000), (15000, 1000))"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad dataset to a maximum review length in words\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZZ1lLQw1Ols"
   },
   "source": [
    "### Encoding Labels\n",
    "\n",
    "The dataset contains labels of the form positive/negative. The following step encodes the labels using ```sklearn's``` ```LabelEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRBnWQGb1cRM"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "num_classes=2 # positive -> 1, negative -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOPPNySt1eDz"
   },
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(train_sentiments)\n",
    "y_test = le.transform(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwlYATD11prp"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1ScFo641sFW"
   },
   "source": [
    "# Bi-directional GRU + Attention Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaPlrBcU-3av"
   },
   "source": [
    "## Build Model Architecture\n",
    "\n",
    "### Attention Layer\n",
    "\n",
    "Attention Layer focuses on attending to the most important words. We sent all the states from our GRU model into the attention model.\n",
    "\n",
    "![](https://i.imgur.com/vbGl6Vl.png)\n",
    "\n",
    "The attention layer produces a context vector\n",
    "\n",
    "![](https://i.imgur.com/nZ71MVd.png)\n",
    "\n",
    "![](https://i.imgur.com/00KyS2e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcP57vjmirh0"
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.init = keras.initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = keras.regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = keras.constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "        \n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        # TF backend doesn't support it\n",
    "        # eij = K.dot(x, self.W) \n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), \n",
    "                              K.reshape(self.W, (features_dim, 1))),\n",
    "                        (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'step_dim': self.step_dim}\n",
    "        base_config = super(AttentionLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional GRUs\n",
    "\n",
    "![](https://i.imgur.com/PuTHi2C.png)\n",
    "\n",
    "![](https://i.imgur.com/ewTg3gB.png)\n",
    "\n",
    "![](https://i.imgur.com/oaBYGeu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "_M8LbmqR1vbO",
    "outputId": "dc783717-986d-4ad4-b32a-7095edce0534"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 01:46:37.181323 139804199487360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 01:46:37.198185 139804199487360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 01:46:37.201365 139804199487360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0806 01:46:38.180671 139804199487360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0806 01:46:38.190708 139804199487360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0806 01:46:38.260683 139804199487360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0806 01:46:38.268632 139804199487360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0806 01:46:38.274364 139804199487360 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 300)         52758000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 256)         330240    \n",
      "_________________________________________________________________\n",
      "attention_layer_1 (Attention (None, 256)               1256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 53,188,313\n",
      "Trainable params: 53,188,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n",
    "GRU_DIM = 128 # total LSTM units\n",
    "\n",
    "inp = keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, trainable=True)(inp)\n",
    "x = keras.layers.Bidirectional(keras.layers.CuDNNGRU(GRU_DIM, return_sequences=True))(x)\n",
    "x = AttentionLayer(MAX_SEQUENCE_LENGTH)(x)\n",
    "x = keras.layers.Dense(GRU_DIM*2, activation='relu')(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "x = keras.layers.Dense(GRU_DIM, activation='relu')(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "outp = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "# initialize the model\n",
    "model = keras.models.Model(inputs=inp, outputs=outp)\n",
    "\n",
    "# make the model parallel\n",
    "#model = multi_gpu_model(model, gpus=2)\n",
    "    \n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRB4rNgo-533"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "uPqowrsh2vFb",
    "outputId": "6bd671fc-1566-40b1-d453-2bc5b38c512c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 3500 samples\n",
      "Epoch 1/2\n",
      "31500/31500 [==============================] - 73s 2ms/step - loss: 0.4235 - acc: 0.7875 - val_loss: 0.2663 - val_acc: 0.8903\n",
      "Epoch 2/2\n",
      "31500/31500 [==============================] - 69s 2ms/step - loss: 0.1581 - acc: 0.9422 - val_loss: 0.2816 - val_acc: 0.8923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26589ebfd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=batch_size, \n",
    "          shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EzC-IW9-7sm"
   },
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kQvfAor127iS",
    "outputId": "452296ff-4d8b-4d10-c2f0-a7d5d40eecb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 19s 1ms/step\n",
      "Accuracy: 89.66%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p_LePG_y4IX5",
    "outputId": "af9f6cb6-7696-48d9-ee9c-f2a3e98aa326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 19s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probs = model.predict(X_test, verbose=1).ravel()\n",
    "predictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "JCifYtx04Ia1",
    "outputId": "d38faa34-0a4b-4968-845e-8ab6143e5f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive']"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "GFUgpD9E4IgE",
    "outputId": "e95e638f-5ad8-4aed-a914-23a4f1285b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89      7490\n",
      "    positive       0.88      0.92      0.90      7510\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.90      0.90      0.90     15000\n",
      "weighted avg       0.90      0.90      0.90     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6550</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>611</td>\n",
       "      <td>6899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6550       940\n",
       "positive       611      6899"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fq9Ccs3Y-_Fh"
   },
   "source": [
    "# Stacked LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aMSEnyBE_BSU"
   },
   "source": [
    "## Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "8As3OAUg4Ijb",
    "outputId": "55c34177-09b2-49ca-96ad-95d1a45786ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1000, 300)         52758000  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1000, 512)         857088    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 1000, 256)         493056    \n",
      "_________________________________________________________________\n",
      "attention_layer_2 (Attention (None, 256)               1256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,208,217\n",
      "Trainable params: 54,208,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n",
    "GRU_DIM = 128 # total LSTM units\n",
    "\n",
    "inp = keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, trainable=True)(inp)\n",
    "x = keras.layers.Bidirectional(keras.layers.CuDNNGRU(GRU_DIM*2, return_sequences=True))(x)\n",
    "x = keras.layers.Bidirectional(keras.layers.CuDNNGRU(GRU_DIM, return_sequences=True))(x)\n",
    "x = AttentionLayer(MAX_SEQUENCE_LENGTH)(x)\n",
    "x = keras.layers.Dense(GRU_DIM*2, activation='relu')(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "x = keras.layers.Dense(GRU_DIM, activation='relu')(x)\n",
    "x = keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "outp = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "# initialize the model\n",
    "model2 = keras.models.Model(inputs=inp, outputs=outp)\n",
    "\n",
    "# make the model parallel\n",
    "#model = multi_gpu_model(model, gpus=2)\n",
    "    \n",
    "model2.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYwqw31s_Ehx"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "atBaIleW5RWI",
    "outputId": "a13c798f-cd35-4193-f8c3-506dfbb1e828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 3500 samples\n",
      "Epoch 1/2\n",
      "31500/31500 [==============================] - 184s 6ms/step - loss: 0.3856 - acc: 0.8070 - val_loss: 0.2457 - val_acc: 0.8937\n",
      "Epoch 2/2\n",
      "31500/31500 [==============================] - 182s 6ms/step - loss: 0.1324 - acc: 0.9517 - val_loss: 0.2669 - val_acc: 0.8911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26404e5550>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "model2.fit(X_train, y_train, epochs=2, batch_size=batch_size, \n",
    "           shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLUkLa-d_IrV"
   },
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lGDVL22K5UZ_",
    "outputId": "c184962d-9845-4b13-ecb6-b9b5e91cd58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 49s 3ms/step\n",
      "Accuracy: 89.63%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model2.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wHnuwJNW5VUT",
    "outputId": "764c2be6-73d8-4671-b744-0e0544d79a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 49s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probs = model2.predict(X_test, verbose=1).ravel()\n",
    "predictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ksyEEPA25XeU",
    "outputId": "c0321626-f7ca-4d96-ab32-81849fddab63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "jMS7pZ3a5XjD",
    "outputId": "f8c03a9e-ad41-421f-a5be-f250f9f2a167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.90      7490\n",
      "    positive       0.91      0.88      0.89      7510\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.90      0.90      0.90     15000\n",
      "weighted avg       0.90      0.90      0.90     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6858</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>924</td>\n",
       "      <td>6586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6858       632\n",
       "positive       924      6586"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvlXJ_T4qw55"
   },
   "source": [
    "# Take Home: Transfer Learning with Pre-trained Embeddings\n",
    "\n",
    "Grab pre-trained embeddings from:\n",
    "\n",
    "- [FastText](https://fasttext.cc/docs/en/english-vectors.html)\n",
    "- [Paragram](https://drive.google.com/file/d/0B9w48e1rj-MOck1fRGxaZW1LU2M/view?usp=sharing)\n",
    "\n",
    "Following tutorial [here](https://github.com/fabric8-analytics/openshift-probable-vulnerabilities/blob/master/notebooks/modeling/deep_learning_models/phase1_baseline_seq_models/GoKube%20Phase1%20-%205%20-%20Security%20vs%20Non-Security%20Modeling.ipynb) build your own models! "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text Classification - Deep Learning Sequential Models - Bidirectional GRUs with Attention.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
