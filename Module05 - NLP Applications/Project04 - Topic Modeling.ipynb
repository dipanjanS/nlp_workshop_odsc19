{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module05%20-%20NLP%20Applications/Project04%20-%20Topic%20Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling on Research Papers\n",
    "\n",
    "We will do an interesting exercise here—build topic models on past research papers\n",
    "from the very popular NIPS conference (now known as the NeurIPS conference). The\n",
    "late professor Sam Roweis compiled an excellent collection of NIPS Conference Papers\n",
    "from Volume 1 – 12, which you can find at https://cs.nyu.edu/~roweis/data.html.\n",
    "An interesting fact is that he obtained this by massaging the OCR’d data from NIPS\n",
    "1-12, which was actually the pre-electronic submission era. Yann LeCun made the data\n",
    "available. There is an even more updated dataset available up to NIPS 17 at http://\n",
    "ai.stanford.edu/~gal/data.html. However, that dataset is in the form of a MAT file, so\n",
    "you might need to do some additional preprocessing before working on it in Python.\n",
    "\n",
    "\n",
    "# The Main Objective\n",
    "\n",
    "Considering our discussion so far, our main objective is pretty simple. Given a whole\n",
    "bunch of conference research papers, can we identify some key themes or topics from\n",
    "these papers by leveraging unsupervised learning? We do not have the liberty of labeled\n",
    "categories telling us what the major themes of every research paper are. Besides that, we\n",
    "are dealing with text data extracted using OCR (optical character recognition). Hence,\n",
    "you can expect misspelled words, words with characters missing, and so on, which\n",
    "makes our problem even more challenging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsTqya546U6q"
   },
   "source": [
    "# Download Data and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "BJaNFsqQ6KGt",
    "outputId": "640bc7b3-5c41-44e5-f5ba-46a700fd311c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-04 18:34:55--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
      "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
      "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12851423 (12M) [application/x-gzip]\n",
      "Saving to: ‘nips12raw_str602.tgz’\n",
      "\n",
      "nips12raw_str602.tg 100%[===================>]  12.26M  14.4MB/s    in 0.9s    \n",
      "\n",
      "2019-08-04 18:34:56 (14.4 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
    "!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "C36S18zo8w3b",
    "outputId": "8ef5b2e7-c0d5-483b-a61b-ad476293803d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oHpf-YxR6XuW",
    "outputId": "98d9aeb3-706a-484e-f682-bb6afd99df34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nips05', 'RAW_DATA_NOTES', 'README_yann', 'nips07', 'idx', 'nips11', 'nips09', 'nips02', 'nips00', 'nips01', 'nips06', 'nips12', 'MATLAB_NOTES', 'nips08', 'nips04', 'nips10', 'nips03', 'orig']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y20UiwtA6pAg"
   },
   "source": [
    "# Load NIPS Research Papers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D3G8nUsJ6h7V",
    "outputId": "3b57a314-f599-4e4f-a4f0-a7dcbe66d615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# Read all texts into a list.\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "JaTh1Jll6kx9",
    "outputId": "f581cd71-bbfe-4198-f49c-74fbb0cc8e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 \n",
      "HIERARCHICAL LEARNING CONTROL - \n",
      "AN APPROACH WITH NEURON-LIKE ASSOCIATIVE MEMORIES \n",
      "E. Ers \n",
      "ISRA Systemtechnik GmbH, Sch6fferstr. 15, D-6100 Darmstadt, FRG \n",
      "H. Tolle \n",
      "TH Darmstadt, Institut fgr Regelungstechnik, \n",
      "Schlograben 1, D-6100 Darmstadt, FRG \n",
      "ABSTRACT \n",
      "Advances in brain theory need two complementary approaches: \n",
      "Analytical investigations by in situ measurements and as well syn- \n",
      "thetic modelling supported by computer simulations to generate \n",
      "suggestive hypothesis on purposeful structures in the neural \n",
      "tissue. In this paper research of the second line is described: \n",
      "Starting from a neurophysiologically inspired model of stimulus- \n",
      "response (S-R) and/or associative memorization and a psychological- \n",
      "ly motivated ministructure for basic control tasks, pre-conditions \n",
      "and conditions are studied for cooperation of such units in a \n",
      "hierarchical organisation, as can be assumed to be the general \n",
      "layout of macrostructures in the brain. \n",
      "I. INTRODUCTION \n",
      "Theoretic modelling in b\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNqkh2nb8qpe"
   },
   "source": [
    "# Basic Text Pre-processing\n",
    "\n",
    "We perform some basic text wrangling or preprocessing before diving into topic\n",
    "modeling. We keep things simple here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Jhsbee7g8lwa",
    "outputId": "7a27795c-adbe-409a-ad2a-4a9076715631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1740/1740 [00:43<00:00, 40.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 41.8 s, sys: 1.25 s, total: 43.1 s\n",
      "Wall time: 43.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "import tqdm\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in tqdm.tqdm(papers):\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "    \n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Cq4EhTwP-I_U",
    "outputId": "b3a78f61-107b-4934-cd0a-a19a9271b52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hierarchical', 'learning', 'control', 'approach', 'neuron', 'like', 'associative', 'memory', 'er', 'isra', 'systemtechnik', 'gmbh', 'sch6fferstr', 'darmstadt', 'frg', 'tolle', 'th', 'darmstadt', 'institut', 'fgr', 'regelungstechnik', 'schlo', 'graben', 'darmstadt', 'frg', 'abstract', 'advance', 'brain', 'theory', 'need', 'two', 'complementary', 'approach', 'analytical', 'investigation', 'situ', 'measurement', 'well', 'syn', 'thetic', 'modelling', 'supported', 'computer', 'simulation', 'generate', 'suggestive', 'hypothesis', 'purposeful', 'structure', 'neural']\n"
     ]
    }
   ],
   "source": [
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFubckun_IYp"
   },
   "source": [
    "# Build a Bi-gram Phrase Model\n",
    "\n",
    "Before feature engineering and vectorization, we want to extract some useful bi-gram\n",
    "based phrases from our research papers and remove some unnecessary terms. We\n",
    "leverage the very useful gensim.models.Phrases class for this. This capability helps us\n",
    "automatically detect common phrases from a stream of sentences, which are typically\n",
    "multi-word expressions/word n-grams. \n",
    "\n",
    "This implementation draws inspiration\n",
    "from the famous paper by Mikolov, et al., “Distributed Representations of Words and\n",
    "Phrases and their Compositionality,” which you can check out at https://arxiv.org/\n",
    "abs/1310.4546. We start by extracting and generating words and bi-grams as phrases for\n",
    "each tokenized research paper. \n",
    "\n",
    "We leverage the `min_count` parameter, which tells us that our model ignores all words and bi-grams with total\n",
    "collected count lower than 20 across the corpus (of the input paper as a list of tokenized\n",
    "sentences). We also use a `threshold` of 20, which tells us that the model accepts specific\n",
    "phrases based on this threshold value so that a phrase of words a followed by b is\n",
    "accepted if the score of the phrase is greater than the threshold of 20. This threshold is\n",
    "dependent on the scoring parameter, which helps us understand how these phrases are\n",
    "scored to understand their influence.\n",
    "Typically the default scorer is used and it’s pretty straightforward to understand.\n",
    "You can check out further details in the documentation at https://radimrehurek.com/\n",
    "gensim/models/phrases.html#gensim.models.phrases.original_scorer and in the\n",
    "previously mentioned research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6IX3-ZbQ-fXp",
    "outputId": "45780848-4d74-4799-dd6d-7efb85695fb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hierarchical', 'learning', 'control', 'approach', 'neuron', 'like', 'associative_memory', 'er', 'isra', 'systemtechnik', 'gmbh', 'sch6fferstr', 'darmstadt', 'frg', 'tolle', 'th', 'darmstadt', 'institut', 'fgr', 'regelungstechnik', 'schlo', 'graben', 'darmstadt', 'frg', 'abstract', 'advance', 'brain', 'theory', 'need', 'two', 'complementary', 'approach', 'analytical', 'investigation', 'situ', 'measurement', 'well', 'syn', 'thetic', 'modelling', 'supported', 'computer_simulation', 'generate', 'suggestive', 'hypothesis', 'purposeful', 'structure', 'neural', 'tissue', 'paper']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_') # higher threshold fewer phrases.\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "KaGCzYSU-jx1",
    "outputId": "9c3282fc-4d33-47dc-e16d-f981b66235d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '1st'), (1, '2nd'), (2, '2sec'), (3, '4th'), (4, '9a'), (5, '9b'), (6, '9th'), (7, 'ability'), (8, 'abstract'), (9, 'abstraction'), (10, 'accept'), (11, 'accordingly'), (12, 'achieved'), (13, 'achieving'), (14, 'aci')]\n",
      "Total Vocabulary Size: 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a lot of unique phrases in our corpus of research papers,\n",
    "based on the preceding output. Several of these terms are not very useful since they are\n",
    "specific to a paper or even a paragraph in a research paper. Hence, it is time to prune\n",
    "our vocabulary and start removing terms. Leveraging document frequency is a great way\n",
    "to achieve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YTiZ2Bxe-tNK",
    "outputId": "98e194eb-416e-427f-fbc5-e4e0f7b1a668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 60% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed all terms that occur fewer than 20 times across all documents and all\n",
    "terms that occur in more than 60% of all the documents. We are interested in finding\n",
    "different themes and topics and not recurring themes. Hence, this suits our scenario\n",
    "perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj2lB4_b_eFO"
   },
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "\n",
    "We can now perform feature engineering by leveraging a simple Bag of Words\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "cp_fhm91-3R-",
    "outputId": "e177a889-d3e7-4b67-d822-cea455b593e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 1), (5, 1), (15, 6), (16, 4), (27, 1), (31, 1), (32, 1), (35, 4), (39, 1), (41, 1), (43, 1), (60, 1), (75, 9), (76, 1), (78, 2), (85, 10), (87, 29), (89, 7), (90, 3), (91, 1), (93, 9), (98, 1), (109, 3), (114, 1), (115, 5), (118, 1), (120, 3), (123, 1), (125, 3), (126, 1), (128, 1), (129, 1), (132, 2), (140, 9), (141, 1), (147, 3), (153, 3), (154, 1), (155, 4), (157, 3), (164, 1), (169, 2), (170, 1), (177, 3), (178, 3), (179, 1), (180, 2), (181, 1), (186, 2), (190, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_oOA652d-6sI",
    "outputId": "74b82e13-3ee3-4e01-85d1-7966821da3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ability', 1), ('abstract', 1), ('activity', 6), ('actual', 4), ('allow', 1), ('american_institute', 1), ('amount', 1), ('another', 4), ('application', 1), ('argument', 1), ('aspect', 1), ('basic', 1), ('brain', 9), ('build', 1), ('built', 2), ('capability', 10), ('cell', 29), ('cerebral', 7), ('cerebral_cortex', 3), ('certain', 1), ('change', 9), ('characterized', 1), ('combination', 3), ('complete', 1), ('complex', 5), ('composed', 1), ('computer_simulation', 3), ('conference', 1), ('connected', 3), ('connection', 1), ('consideration', 1), ('considered', 1), ('control', 2), ('cortical', 9), ('could', 1), ('defined', 3), ('design', 3), ('detail', 1), ('detailed', 4), ('development', 3), ('direction', 1), ('distributed', 2), ('distribution', 1), ('dynamic', 3), ('ed', 3), ('edelman', 1), ('effect', 2), ('effective', 1), ('element', 2), ('end', 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aAjuxxdH--fn",
    "outputId": "dbe56299-2754-40aa-980b-40cc5876d525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ty46zp-_DHT"
   },
   "source": [
    "# Topic Models with Latent Semantic Indexing (LSI)\n",
    "\n",
    "\n",
    "Our first technique is Latent Semantic Indexing (LSI), which was developed in the 1970s\n",
    "as a statistical technique to correlate semantically linked terms from corpora. LSI is not\n",
    "just used for text summarization, but also in information retrieval and search. LSI uses\n",
    "the very popular Singular Value Decomposition (SVD) technique.\n",
    "\n",
    "The main principle behind LSI is that similar\n",
    "terms tend to be used in the same context and hence tend to co-occur more. The term\n",
    "LSI comes from the fact that this technique has the ability to uncover latent hidden terms\n",
    "that correlate semantically to form topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HSfb1NnmDn-y",
    "outputId": "2465b65d-a2db-487d-9cc3-6e84f889ab76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 45s, sys: 1min 40s, total: 9min 25s\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "TOTAL_TOPICS = 10\n",
    "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS,\n",
    "                                 onepass=True, chunksize=1740, power_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "u_XyNljwDsVr",
    "outputId": "6172eb8b-347e-477c-f33a-d889fdef5907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n",
      "\n",
      "Topic #2:\n",
      "0.487*\"neuron\" + 0.396*\"cell\" + -0.257*\"state\" + 0.191*\"response\" + -0.187*\"training\" + 0.170*\"stimulus\" + 0.117*\"activity\" + -0.109*\"class\" + 0.099*\"spike\" + 0.097*\"pattern\" + 0.096*\"circuit\" + 0.096*\"synaptic\" + -0.095*\"vector\" + 0.090*\"signal\" + 0.090*\"firing\" + 0.088*\"visual\" + -0.084*\"classifier\" + -0.083*\"action\" + -0.078*\"word\" + 0.078*\"cortical\"\n",
      "\n",
      "Topic #3:\n",
      "-0.627*\"state\" + 0.395*\"image\" + -0.219*\"neuron\" + 0.209*\"feature\" + -0.188*\"action\" + 0.137*\"unit\" + 0.131*\"object\" + -0.130*\"control\" + 0.129*\"training\" + -0.109*\"policy\" + 0.103*\"classifier\" + 0.090*\"class\" + -0.081*\"step\" + -0.081*\"dynamic\" + 0.080*\"classification\" + 0.078*\"layer\" + 0.076*\"recognition\" + -0.074*\"reinforcement_learning\" + 0.069*\"representation\" + 0.068*\"pattern\"\n",
      "\n",
      "Topic #4:\n",
      "-0.686*\"unit\" + 0.433*\"image\" + -0.182*\"pattern\" + -0.131*\"layer\" + -0.123*\"hidden_unit\" + -0.121*\"net\" + -0.114*\"training\" + 0.112*\"feature\" + -0.109*\"activation\" + -0.107*\"rule\" + 0.097*\"neuron\" + -0.078*\"word\" + 0.070*\"pixel\" + -0.070*\"connection\" + 0.067*\"object\" + 0.065*\"state\" + 0.060*\"distribution\" + 0.059*\"face\" + -0.057*\"architecture\" + 0.055*\"estimate\"\n",
      "\n",
      "Topic #5:\n",
      "-0.428*\"image\" + -0.348*\"state\" + 0.266*\"neuron\" + -0.264*\"unit\" + 0.181*\"training\" + 0.174*\"class\" + -0.168*\"object\" + 0.167*\"classifier\" + -0.147*\"action\" + -0.122*\"visual\" + 0.117*\"vector\" + 0.115*\"node\" + 0.105*\"distribution\" + -0.103*\"motion\" + -0.099*\"feature\" + 0.097*\"classification\" + -0.097*\"control\" + -0.095*\"task\" + -0.087*\"cell\" + -0.083*\"representation\"\n",
      "\n",
      "Topic #6:\n",
      "0.660*\"cell\" + -0.508*\"neuron\" + -0.213*\"image\" + -0.103*\"chip\" + -0.097*\"unit\" + 0.093*\"response\" + -0.090*\"object\" + 0.083*\"rat\" + 0.076*\"distribution\" + -0.070*\"circuit\" + 0.069*\"probability\" + 0.064*\"stimulus\" + -0.061*\"memory\" + -0.058*\"analog\" + -0.058*\"activation\" + 0.055*\"class\" + -0.053*\"bit\" + -0.052*\"net\" + 0.051*\"cortical\" + 0.050*\"firing\"\n",
      "\n",
      "Topic #7:\n",
      "0.353*\"word\" + -0.281*\"unit\" + 0.272*\"training\" + 0.257*\"classifier\" + 0.177*\"recognition\" + -0.159*\"distribution\" + 0.152*\"feature\" + 0.144*\"state\" + 0.142*\"pattern\" + -0.141*\"vector\" + 0.128*\"cell\" + 0.128*\"task\" + -0.122*\"approximation\" + -0.121*\"variable\" + -0.110*\"equation\" + 0.107*\"classification\" + -0.106*\"noise\" + 0.103*\"class\" + -0.101*\"matrix\" + 0.098*\"neuron\"\n",
      "\n",
      "Topic #8:\n",
      "0.303*\"pattern\" + -0.243*\"signal\" + -0.236*\"control\" + -0.202*\"training\" + 0.181*\"rule\" + 0.178*\"state\" + -0.167*\"noise\" + 0.166*\"class\" + -0.162*\"word\" + 0.155*\"cell\" + 0.154*\"feature\" + -0.147*\"motion\" + -0.140*\"task\" + 0.127*\"node\" + 0.124*\"neuron\" + -0.116*\"target\" + -0.114*\"circuit\" + 0.114*\"probability\" + 0.110*\"classifier\" + 0.109*\"image\"\n",
      "\n",
      "Topic #9:\n",
      "-0.472*\"node\" + -0.254*\"circuit\" + 0.214*\"word\" + -0.201*\"chip\" + 0.190*\"neuron\" + 0.172*\"stimulus\" + -0.160*\"classifier\" + -0.152*\"current\" + 0.147*\"feature\" + -0.146*\"voltage\" + 0.145*\"distribution\" + -0.141*\"control\" + -0.124*\"rule\" + -0.110*\"layer\" + -0.105*\"analog\" + -0.091*\"tree\" + 0.084*\"response\" + 0.080*\"state\" + 0.079*\"probability\" + 0.079*\"estimate\"\n",
      "\n",
      "Topic #10:\n",
      "0.518*\"word\" + -0.254*\"training\" + 0.236*\"vector\" + -0.222*\"task\" + -0.194*\"pattern\" + -0.156*\"classifier\" + 0.149*\"node\" + 0.146*\"recognition\" + -0.139*\"control\" + 0.138*\"sequence\" + -0.126*\"rule\" + 0.125*\"circuit\" + 0.123*\"cell\" + -0.113*\"action\" + -0.105*\"neuron\" + 0.094*\"hmm\" + 0.093*\"character\" + 0.088*\"chip\" + 0.088*\"matrix\" + 0.085*\"structure\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a moment to understand these results. A brief recap on the LSI model—\n",
    "it is based on the principle that words that are used in the same contexts tend to have\n",
    "similar meanings. You can observe in this output that each topic is a combination\n",
    "of terms (which basically tend to convey an overall sense of the topic) and weights.\n",
    "Now the problem here is that we have both positive and negative weights. What does\n",
    "that mean?\n",
    "\n",
    "Based on existing research and my interpretations, considering we are reducing\n",
    "the dimensionality here to a 10-dimensional space based on the number of topics, the\n",
    "sign on each term indicates a sense of direction or orientation in the vector space for a\n",
    "particular topic. The higher the weight, the more important the contribution. So similar\n",
    "correlated terms have the same sign or direction. Hence, it is perfectly possible for a\n",
    "topic to have two different sub-themes based on the sign or orientation of terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uZo_W72DFdRQ",
    "outputId": "3c0a1402-757e-445a-fd53-3f6ca142c7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.487), ('cell', 0.396), ('response', 0.191), ('stimulus', 0.17), ('activity', 0.117), ('spike', 0.099), ('pattern', 0.097), ('circuit', 0.096), ('synaptic', 0.096), ('signal', 0.09), ('firing', 0.09), ('visual', 0.088), ('cortical', 0.078)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.257), ('training', -0.187), ('class', -0.109), ('vector', -0.095), ('classifier', -0.084), ('action', -0.083), ('word', -0.078)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.395), ('feature', 0.209), ('unit', 0.137), ('object', 0.131), ('training', 0.129), ('classifier', 0.103), ('class', 0.09), ('classification', 0.08), ('layer', 0.078), ('recognition', 0.076), ('representation', 0.069), ('pattern', 0.068)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.627), ('neuron', -0.219), ('action', -0.188), ('control', -0.13), ('policy', -0.109), ('step', -0.081), ('dynamic', -0.081), ('reinforcement_learning', -0.074)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.433), ('feature', 0.112), ('neuron', 0.097), ('pixel', 0.07), ('object', 0.067), ('state', 0.065), ('distribution', 0.06), ('face', 0.059), ('estimate', 0.055)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -0.686), ('pattern', -0.182), ('layer', -0.131), ('hidden_unit', -0.123), ('net', -0.121), ('training', -0.114), ('activation', -0.109), ('rule', -0.107), ('word', -0.078), ('connection', -0.07), ('architecture', -0.057)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.266), ('training', 0.181), ('class', 0.174), ('classifier', 0.167), ('vector', 0.117), ('node', 0.115), ('distribution', 0.105), ('classification', 0.097)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.428), ('state', -0.348), ('unit', -0.264), ('object', -0.168), ('action', -0.147), ('visual', -0.122), ('motion', -0.103), ('feature', -0.099), ('control', -0.097), ('task', -0.095), ('cell', -0.087), ('representation', -0.083)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.66), ('response', 0.093), ('rat', 0.083), ('distribution', 0.076), ('probability', 0.069), ('stimulus', 0.064), ('class', 0.055), ('cortical', 0.051), ('firing', 0.05)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.508), ('image', -0.213), ('chip', -0.103), ('unit', -0.097), ('object', -0.09), ('circuit', -0.07), ('memory', -0.061), ('analog', -0.058), ('activation', -0.058), ('bit', -0.053), ('net', -0.052)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.353), ('training', 0.272), ('classifier', 0.257), ('recognition', 0.177), ('feature', 0.152), ('state', 0.144), ('pattern', 0.142), ('cell', 0.128), ('task', 0.128), ('classification', 0.107), ('class', 0.103), ('neuron', 0.098)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -0.281), ('distribution', -0.159), ('vector', -0.141), ('approximation', -0.122), ('variable', -0.121), ('equation', -0.11), ('noise', -0.106), ('matrix', -0.101)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('pattern', 0.303), ('rule', 0.181), ('state', 0.178), ('class', 0.166), ('cell', 0.155), ('feature', 0.154), ('node', 0.127), ('neuron', 0.124), ('probability', 0.114), ('classifier', 0.11), ('image', 0.109)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('signal', -0.243), ('control', -0.236), ('training', -0.202), ('noise', -0.167), ('word', -0.162), ('motion', -0.147), ('task', -0.14), ('target', -0.116), ('circuit', -0.114)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.214), ('neuron', 0.19), ('stimulus', 0.172), ('feature', 0.147), ('distribution', 0.145), ('response', 0.084), ('state', 0.08), ('probability', 0.079), ('estimate', 0.079)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -0.472), ('circuit', -0.254), ('chip', -0.201), ('classifier', -0.16), ('current', -0.152), ('voltage', -0.146), ('control', -0.141), ('rule', -0.124), ('layer', -0.11), ('analog', -0.105), ('tree', -0.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.518), ('vector', 0.236), ('node', 0.149), ('recognition', 0.146), ('sequence', 0.138), ('circuit', 0.125), ('cell', 0.123), ('hmm', 0.094), ('character', 0.093), ('chip', 0.088), ('matrix', 0.088), ('structure', 0.085)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('training', -0.254), ('task', -0.222), ('pattern', -0.194), ('classifier', -0.156), ('control', -0.139), ('rule', -0.126), ('action', -0.113), ('neuron', -0.105)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make things better? Well, it’s definitely a lot better than the previous\n",
    "interpretation. Here we can see clear themes of modeling being applied in chips and\n",
    "electronic devices, classification and recognition models, neural models talking about\n",
    "the human brain components like cells, stimuli, neurons, cortical components, and\n",
    "even themes around reinforcement learning! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LSI and SVD\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/BglSwGK.png)\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/nJc79tK.png)\n",
    "\n",
    "- __M__ is typically known as the term-document matrix and is usually\n",
    "obtained after feature engineering on the preprocessed text data,\n",
    "where each row of the matrix represents a term and each column\n",
    "represents a text document.\n",
    "\n",
    "- __U__ is known as the term-topic matrix where each row of the matrix\n",
    "represents a term and each column represents a topic. It’s useful for\n",
    "getting the influential terms for each topic when we multiply this by\n",
    "the singular values.\n",
    "\n",
    "- __S__ is the matrix or array that consists of the list of singular values\n",
    "obtained after low-rank SVD, which is typically equal to the number\n",
    "of topics we decide prior to this operation.\n",
    "\n",
    "- __VT__ is the topic-document matrix, which if you transpose, you get\n",
    "the document-topic matrix, which is useful in knowing how much\n",
    "influence each topic has on each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s try to get the three major matrices (U, S, and VT) from our topic model, which uses SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "LHfigj6ZFr02",
    "outputId": "c5474b50-553c-45ce-aace-2e29843e8518"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:502: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_topic = lsi_bow.projection.u\n",
    "singular_values = lsi_bow.projection.s\n",
    "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the preceding output shows, we have a term-topic matrix, singular values, and a\n",
    "topic-document matrix. We can transpose the topic-document matrix to form a documenttopic matrix and that would help us see the proportion of each topic per document (a larger\n",
    "proportion means the topic is more dominant in the document). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "Oo-qz3B-GJj3",
    "outputId": "80e3633b-c321-4d8d-e701-4651c335b3a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0   0.027  0.006 -0.016  0.001 -0.012  0.006  0.001 -0.029 -0.026 -0.025\n",
       "1   0.033  0.071 -0.017  0.003  0.018  0.009  0.020  0.019  0.011 -0.011\n",
       "2   0.041 -0.014 -0.017 -0.032 -0.018 -0.003 -0.062 -0.005  0.001  0.021\n",
       "3   0.040 -0.046 -0.121  0.017 -0.071  0.003  0.030  0.027 -0.004 -0.022\n",
       "4   0.019  0.006 -0.003 -0.000  0.005  0.011 -0.017  0.007 -0.005  0.011\n",
       "5   0.054  0.102 -0.009 -0.019 -0.006  0.067  0.044 -0.004  0.082 -0.056\n",
       "6   0.015  0.023 -0.010 -0.005  0.010 -0.013 -0.001  0.005 -0.004  0.004\n",
       "7   0.013  0.035 -0.010  0.009  0.014 -0.026  0.005 -0.002  0.018 -0.012\n",
       "8   0.055 -0.006  0.017 -0.086 -0.105 -0.022 -0.030 -0.002  0.005 -0.037\n",
       "9   0.061  0.004  0.048 -0.127 -0.050 -0.027 -0.063  0.116  0.026  0.061\n",
       "10  0.012  0.005 -0.009  0.008  0.014 -0.006 -0.012 -0.006  0.006 -0.002\n",
       "11  0.032  0.036 -0.011 -0.014  0.035 -0.052  0.016  0.043  0.010 -0.029\n",
       "12  0.014 -0.009 -0.019  0.008  0.006 -0.004 -0.012  0.018 -0.017  0.010\n",
       "13  0.023  0.003  0.006  0.031 -0.016 -0.004 -0.028 -0.021 -0.046  0.021\n",
       "14  0.022 -0.004 -0.033  0.008 -0.029  0.008  0.009  0.007  0.016  0.003"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most dominant topics for some sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8Tt_oNC5OpJw",
    "outputId": "179e958a-ce5c-482b-e290-b4334339bc7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[693, 708, 460]"
      ]
     },
     "execution_count": 175,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_paper_patterns = ['Feudal Reinforcement Learning \\nPeter', 'Illumination-Invariant Face Recognition with a', 'Improved Hidden Markov Model Speech Recognition']\n",
    "sample_paper_idxs = [idx for pattern in sample_paper_patterns \n",
    "                            for idx, content in enumerate(papers) \n",
    "                                if pattern in content]\n",
    "sample_paper_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pcVLAK-ZGQ4-",
    "outputId": "4c39396c-cce0-4f8d-a2ae-af8c0d6eb915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #693:\n",
      "Dominant Topics (top 3): ['T5', 'T3', 'T10']\n",
      "Paper Summary:\n",
      "Feudal Reinforcement Learning \n",
      "Peter Dayan \n",
      "CNL \n",
      "The Salk Institute \n",
      "PO Box 85800 \n",
      "San Diego CA 92186-5800, USA \n",
      "dayanhelmholtz. sdsc. edu \n",
      "Geoffrey E Hinton \n",
      "Department of Computer Science \n",
      "University of Toronto \n",
      "6 Kings College Road, Toronto, \n",
      "Canada M5S 1A4 \n",
      "hintonai. toronto. edu \n",
      "Abstract \n",
      "One way to speed up reinforcement learning is to enable learning to \n",
      "happen simultaneously at multiple resolutions in space and time. \n",
      "This paper shows how to create a Q-learning managerial hierarchy \n",
      "i\n",
      "\n",
      "Document #708:\n",
      "Dominant Topics (top 3): ['T4', 'T3', 'T5']\n",
      "Paper Summary:\n",
      "Illumination-Invariant Face Recognition with a \n",
      "Contrast Sensitive Silicon Retina \n",
      "Joachim M. Buhmann \n",
      "Rheinische Friedrich-Wilhelms-Universitfit \n",
      "Institut ftir Informatik II, R6merstrage 164 \n",
      "D-53117 Bonn, Germany \n",
      "Martin Lades \n",
      "Ruhr-Universitfit Bochum \n",
      "Institut ftir Neuroinformatik \n",
      "D-44780 Bochum, Germany \n",
      "Frank Eeckman \n",
      "Lawrence Livermore National Laboratory \n",
      "ISCR, P.O.Box 808, L-426 \n",
      "Livermore, CA 94551 \n",
      "Abstract \n",
      "Changes in lighting conditions strongly effect the performance and reli- \n",
      "ab\n",
      "\n",
      "Document #460:\n",
      "Dominant Topics (top 3): ['T7', 'T10', 'T2']\n",
      "Paper Summary:\n",
      "Improved Hidden Markov Model \n",
      "Speech Recognition Using \n",
      "Radial Basis Function Networks \n",
      "Elliot Singer and Richard P. Lippmann \n",
      "Lincoln Laboratory, MIT \n",
      "Lexington, MA 02173-9108, USA \n",
      "Abstract \n",
      "A high performance speaker-independent isolated-word hybrid speech rec- \n",
      "ognizer was developed which combines Hidden Markov Models (HMMs) \n",
      "and Radial Basis Function (RBF) neural networks. In recognition ex- \n",
      "periments using a speaker-independent E-set database, the hybrid rec- \n",
      "ognizer had an error rate of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = sample_paper_idxs\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LSI Models from Scratch\n",
    "\n",
    "Based on what we mentioned earlier, the heart of LSI models involves Singular Value\n",
    "Decomposition (SVD). Here, we try to implement an LSI topic model from scratch using\n",
    "low-rank SVD. The first step in SVD is to get the source matrix, which is typically a term-document matrix. We can obtain it from Gensim by converting the sparse Bag of Words\n",
    "representation into a dense matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "wfw4r4QrGmWW",
    "outputId": "2056ac40-bdda-4943-e5f4-93f3ccda21b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:502: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7756, 1740)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ..., 18.,  0.,  4.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_matrix = gensim.matutils.corpus2dense(corpus=bow_corpus, num_terms=len(dictionary))\n",
    "print(td_matrix.shape)\n",
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "jDP8mWVVIYUb",
    "outputId": "c1c9735d-6ee2-44a6-b2cc-a55bae8c0905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1st', '2nd', '4th', ..., 'support_vector', 'mozer_jordan',\n",
       "       'kearns_solla'], dtype='<U28')"
      ]
     },
     "execution_count": 195,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = np.array(list(dictionary.values()))\n",
    "print('Total vocabulary size:', len(vocabulary))\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kgMm5p64Ib7w",
    "outputId": "44ef54fe-0e81-455b-e09a-4ec8555ef096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'achieving'"
      ]
     },
     "execution_count": 196,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now perform low-rank SVD on our term document matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3fQnxKApIiPW",
    "outputId": "0f3f14e9-9599-4c25-dbce-59aa7f3ce843"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 197,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "u, s, vt = svds(td_matrix, k=TOTAL_TOPICS, maxiter=10000)\n",
    "term_topic = u\n",
    "singular_values = s\n",
    "topic_document = vt\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QUAK3NBvInXL",
    "outputId": "f867aa4f-fd24-403b-8392-b418ed55e4a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7756)"
      ]
     },
     "execution_count": 198,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_weights = term_topic.transpose() * singular_values[:, None]\n",
    "tt_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ph-2yxSxItF_",
    "outputId": "1a7ea25c-ae19-4436-bb40-cddb365dd2a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('training', 92.618), ('task', 80.732), ('pattern', 70.619), ('classifier', 56.988), ('control', 50.676), ('rule', 45.925), ('action', 41.202), ('neuron', 38.194)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -188.487), ('vector', -85.973), ('node', -54.378), ('recognition', -53.231), ('sequence', -50.351), ('circuit', -45.395), ('cell', -44.811), ('hmm', -34.085), ('character', -34.022), ('chip', -32.161), ('matrix', -32.093), ('structure', -30.993)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('word', 78.349), ('neuron', 69.793), ('stimulus', 63.233), ('feature', 53.819), ('distribution', 53.119), ('response', 30.954), ('state', 29.343), ('probability', 29.1), ('estimate', 28.908)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -173.276), ('circuit', -92.999), ('chip', -73.593), ('classifier', -58.717), ('current', -55.844), ('voltage', -53.489), ('control', -51.709), ('rule', -45.294), ('layer', -40.265), ('analog', -38.344), ('tree', -33.483)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('pattern', 116.971), ('rule', 69.783), ('state', 68.605), ('class', 64.259), ('cell', 59.979), ('feature', 59.606), ('node', 49.176), ('neuron', 47.997), ('probability', 43.812), ('classifier', 42.612), ('image', 42.061)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('signal', -93.805), ('control', -91.041), ('training', -77.88), ('noise', -64.397), ('word', -62.392), ('motion', -56.699), ('task', -53.883), ('target', -44.765), ('circuit', -44.129)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('unit', 117.727), ('distribution', 66.719), ('vector', 58.881), ('approximation', 50.931), ('variable', 50.83), ('equation', 46.229), ('noise', 44.248), ('matrix', 42.214)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -147.792), ('training', -113.693), ('classifier', -107.386), ('recognition', -73.948), ('feature', -63.454), ('state', -60.126), ('pattern', -59.561), ('cell', -53.769), ('task', -53.693), ('classification', -44.936), ('class', -43.161), ('neuron', -41.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 220.116), ('image', 92.391), ('chip', 44.422), ('unit', 41.922), ('object', 39.001), ('circuit', 30.444), ('memory', 26.475), ('analog', 25.207), ('activation', 24.953), ('bit', 22.997), ('net', 22.699)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -285.803), ('response', -40.216), ('rat', -35.975), ('distribution', -33.085), ('probability', -29.79), ('stimulus', -27.789), ('class', -24.02), ('cortical', -22.185), ('firing', -21.66)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 130.053), ('training', 88.669), ('class', 85.213), ('classifier', 81.92), ('vector', 57.531), ('node', 56.342), ('distribution', 51.622), ('classification', 47.645)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -209.796), ('state', -170.207), ('unit', -129.105), ('object', -82.185), ('action', -72.136), ('visual', -59.503), ('motion', -50.605), ('feature', -48.665), ('control', -47.427), ('task', -46.496), ('cell', -42.366), ('representation', -40.563)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('unit', 341.83), ('pattern', 90.771), ('layer', 65.337), ('hidden_unit', 61.12), ('net', 60.035), ('training', 56.741), ('activation', 54.268), ('rule', 53.377), ('word', 38.902), ('connection', 34.618), ('architecture', 28.439)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -215.856), ('feature', -55.647), ('neuron', -48.496), ('pixel', -35.095), ('object', -33.584), ('state', -32.543), ('distribution', -29.977), ('face', -29.256), ('estimate', -27.556)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('image', 229.287), ('feature', 121.397), ('unit', 79.44), ('object', 76.204), ('training', 75.153), ('classifier', 59.872), ('class', 52.527), ('classification', 46.696), ('layer', 45.149), ('recognition', 44.192), ('representation', 40.179), ('pattern', 39.252)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -364.388), ('neuron', -127.022), ('action', -109.245), ('control', -75.369), ('policy', -63.103), ('step', -47.226), ('dynamic', -46.907), ('reinforcement_learning', -42.747)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('state', 161.465), ('training', 117.319), ('class', 68.732), ('vector', 59.558), ('classifier', 52.589), ('action', 52.113), ('word', 49.239)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -306.151), ('cell', -249.243), ('response', -119.758), ('stimulus', -106.762), ('activity', -73.499), ('spike', -62.039), ('pattern', -60.957), ('circuit', -60.602), ('synaptic', -60.282), ('signal', -56.665), ('firing', -56.597), ('visual', -55.571), ('cortical', -48.867)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('unit', 260.793), ('state', 258.146), ('training', 227.312), ('neuron', 215.681), ('pattern', 197.232), ('image', 175.735), ('vector', 170.154), ('feature', 151.547), ('cell', 148.138), ('layer', 133.593), ('task', 122.389), ('class', 117.849), ('probability', 110.526), ('signal', 108.232), ('step', 105.202), ('response', 104.465), ('representation', 103.255), ('noise', 100.573), ('rule', 99.611), ('distribution', 98.973)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(tt_weights), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([tt_weights[row, columns] \n",
    "                             for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weights[n]\n",
    "    term_weights = sorted([(t, w) for t, w in zip(terms, weights)], \n",
    "                          key=lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "ofQtyR3LIwiM",
    "outputId": "2d3a81ef-8305-41e5-c199-fd49615f2480"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0   0.025 -0.026 -0.029 -0.001 -0.006 -0.012 -0.001 -0.016 -0.006  0.027\n",
       "1   0.011  0.011  0.019 -0.020 -0.009  0.018 -0.003 -0.017 -0.071  0.033\n",
       "2  -0.021  0.001 -0.005  0.062  0.003 -0.018  0.032 -0.017  0.014  0.041\n",
       "3   0.022 -0.004  0.027 -0.030 -0.003 -0.071 -0.017 -0.121  0.046  0.040\n",
       "4  -0.011 -0.005  0.007  0.017 -0.011  0.005  0.000 -0.003 -0.006  0.019\n",
       "5   0.056  0.082 -0.004 -0.044 -0.067 -0.006  0.019 -0.009 -0.102  0.054\n",
       "6  -0.004 -0.004  0.005  0.001  0.013  0.010  0.005 -0.010 -0.023  0.015\n",
       "7   0.012  0.018 -0.002 -0.005  0.026  0.014 -0.009 -0.010 -0.035  0.013\n",
       "8   0.037  0.005 -0.002  0.030  0.022 -0.105  0.086  0.017  0.006  0.055\n",
       "9  -0.061  0.026  0.116  0.063  0.027 -0.050  0.127  0.048 -0.004  0.061\n",
       "10  0.002  0.006 -0.006  0.012  0.006  0.014 -0.008 -0.009 -0.005  0.012\n",
       "11  0.029  0.010  0.043 -0.016  0.052  0.035  0.014 -0.011 -0.036  0.032\n",
       "12 -0.010 -0.017  0.018  0.012  0.004  0.006 -0.008 -0.019  0.009  0.014\n",
       "13 -0.021 -0.046 -0.021  0.028  0.004 -0.016 -0.031  0.006 -0.003  0.023\n",
       "14 -0.003  0.016  0.007 -0.009 -0.008 -0.029 -0.008 -0.033  0.004  0.022"
      ]
     },
     "execution_count": 200,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ttwkin6QI-v4",
    "outputId": "4e3c989d-f7ca-4a86-de28-a8cf251583bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #693:\n",
      "Dominant Topics (top 3): ['T6', 'T1', 'T8']\n",
      "Paper Summary:\n",
      "Feudal Reinforcement Learning \n",
      "Peter Dayan \n",
      "CNL \n",
      "The Salk Institute \n",
      "PO Box 85800 \n",
      "San Diego CA 92186-5800, USA \n",
      "dayanhelmholtz. sdsc. edu \n",
      "Geoffrey E Hinton \n",
      "Department of Computer Science \n",
      "University of Toronto \n",
      "6 Kings College Road, Toronto, \n",
      "Canada M5S 1A4 \n",
      "hintonai. toronto. edu \n",
      "Abstract \n",
      "One way to speed up reinforcement learning is to enable learning to \n",
      "happen simultaneously at multiple resolutions in space and time. \n",
      "This paper shows how to create a Q-learning managerial hierarchy \n",
      "i\n",
      "\n",
      "Document #708:\n",
      "Dominant Topics (top 3): ['T7', 'T8', 'T6']\n",
      "Paper Summary:\n",
      "Illumination-Invariant Face Recognition with a \n",
      "Contrast Sensitive Silicon Retina \n",
      "Joachim M. Buhmann \n",
      "Rheinische Friedrich-Wilhelms-Universitfit \n",
      "Institut ftir Informatik II, R6merstrage 164 \n",
      "D-53117 Bonn, Germany \n",
      "Martin Lades \n",
      "Ruhr-Universitfit Bochum \n",
      "Institut ftir Neuroinformatik \n",
      "D-44780 Bochum, Germany \n",
      "Frank Eeckman \n",
      "Lawrence Livermore National Laboratory \n",
      "ISCR, P.O.Box 808, L-426 \n",
      "Livermore, CA 94551 \n",
      "Abstract \n",
      "Changes in lighting conditions strongly effect the performance and reli- \n",
      "ab\n",
      "\n",
      "Document #460:\n",
      "Dominant Topics (top 3): ['T4', 'T1', 'T9']\n",
      "Paper Summary:\n",
      "Improved Hidden Markov Model \n",
      "Speech Recognition Using \n",
      "Radial Basis Function Networks \n",
      "Elliot Singer and Richard P. Lippmann \n",
      "Lincoln Laboratory, MIT \n",
      "Lexington, MA 02173-9108, USA \n",
      "Abstract \n",
      "A high performance speaker-independent isolated-word hybrid speech rec- \n",
      "ognizer was developed which combines Hidden Markov Models (HMMs) \n",
      "and Radial Basis Function (RBF) neural networks. In recognition ex- \n",
      "periments using a speaker-independent E-set database, the hybrid rec- \n",
      "ognizer had an error rate of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = sample_paper_idxs\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUb8ZKJXJI-4"
   },
   "source": [
    "# Topic Models with Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "The Latent Dirichlet Allocation (LDA) technique is a generative probabilistic model in\n",
    "which each document is assumed to have a combination of topics similar to a probabilistic\n",
    "Latent Semantic Indexing model. In this case, the latent topics contain a Dirichlet\n",
    "prior over them. The math behind in this technique is pretty involved, so we will try to\n",
    "summarize it since going it specific details is out of the current scope.\n",
    "\n",
    "![](https://i.imgur.com/l23JAvE.png)\n",
    "\n",
    "Simplyfying the LDA model process:\n",
    "\n",
    "![](https://i.imgur.com/0BXCaUi.png)\n",
    "\n",
    "![](https://i.imgur.com/ioiUAxX.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "083_UQPlJZy_",
    "outputId": "96a68895-34c0-4963-e064-5c5b5c6b5757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 1.94 s, total: 1min 54s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n",
    "                                   alpha='auto', eta='auto', random_state=42,\n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "IF9KX9UARO1r",
    "outputId": "3b6b048a-0bca-48b4-80d4-4aa63b864a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.022*\"image\" + 0.009*\"object\" + 0.008*\"feature\" + 0.007*\"vector\" + 0.004*\"bit\" + 0.004*\"pixel\" + 0.004*\"view\" + 0.004*\"chip\" + 0.004*\"search\" + 0.004*\"processor\" + 0.003*\"constraint\" + 0.003*\"code\" + 0.003*\"region\" + 0.003*\"parallel\" + 0.003*\"distance\" + 0.003*\"solution\" + 0.003*\"matrix\" + 0.003*\"surface\" + 0.003*\"memory\" + 0.003*\"application\"\n",
      "\n",
      "Topic #2:\n",
      "0.011*\"unit\" + 0.009*\"structure\" + 0.008*\"variable\" + 0.007*\"node\" + 0.007*\"representation\" + 0.006*\"tree\" + 0.006*\"vector\" + 0.006*\"cluster\" + 0.005*\"image\" + 0.004*\"probability\" + 0.004*\"pattern\" + 0.004*\"clustering\" + 0.004*\"level\" + 0.004*\"feature\" + 0.004*\"graph\" + 0.004*\"object\" + 0.003*\"mixture\" + 0.003*\"distribution\" + 0.003*\"layer\" + 0.003*\"local\"\n",
      "\n",
      "Topic #3:\n",
      "0.023*\"state\" + 0.012*\"action\" + 0.011*\"control\" + 0.007*\"policy\" + 0.007*\"step\" + 0.006*\"task\" + 0.006*\"reinforcement_learning\" + 0.005*\"optimal\" + 0.005*\"controller\" + 0.005*\"environment\" + 0.004*\"robot\" + 0.004*\"goal\" + 0.004*\"reward\" + 0.004*\"expert\" + 0.003*\"td\" + 0.003*\"agent\" + 0.003*\"local\" + 0.003*\"cost\" + 0.003*\"current\" + 0.003*\"probability\"\n",
      "\n",
      "Topic #4:\n",
      "0.014*\"training\" + 0.010*\"feature\" + 0.010*\"word\" + 0.009*\"classifier\" + 0.009*\"classification\" + 0.009*\"recognition\" + 0.008*\"pattern\" + 0.007*\"class\" + 0.006*\"trained\" + 0.005*\"task\" + 0.005*\"speech\" + 0.004*\"test\" + 0.004*\"unit\" + 0.004*\"training_set\" + 0.004*\"character\" + 0.004*\"experiment\" + 0.004*\"rule\" + 0.004*\"face\" + 0.004*\"representation\" + 0.003*\"layer\"\n",
      "\n",
      "Topic #5:\n",
      "0.022*\"neuron\" + 0.017*\"cell\" + 0.009*\"circuit\" + 0.007*\"response\" + 0.007*\"current\" + 0.006*\"synaptic\" + 0.006*\"spike\" + 0.006*\"voltage\" + 0.005*\"activity\" + 0.005*\"pattern\" + 0.004*\"firing\" + 0.004*\"chip\" + 0.004*\"synapsis\" + 0.004*\"connection\" + 0.004*\"signal\" + 0.004*\"neural\" + 0.004*\"stimulus\" + 0.004*\"layer\" + 0.004*\"effect\" + 0.004*\"cortical\"\n",
      "\n",
      "Topic #6:\n",
      "0.007*\"distribution\" + 0.007*\"training\" + 0.006*\"noise\" + 0.005*\"estimate\" + 0.005*\"vector\" + 0.005*\"equation\" + 0.004*\"approximation\" + 0.004*\"gaussian\" + 0.004*\"sample\" + 0.004*\"prediction\" + 0.004*\"prior\" + 0.004*\"density\" + 0.004*\"linear\" + 0.004*\"variance\" + 0.004*\"rate\" + 0.004*\"average\" + 0.004*\"matrix\" + 0.003*\"optimal\" + 0.003*\"solution\" + 0.003*\"probability\"\n",
      "\n",
      "Topic #7:\n",
      "0.010*\"class\" + 0.007*\"let\" + 0.006*\"vector\" + 0.006*\"bound\" + 0.006*\"theorem\" + 0.005*\"linear\" + 0.005*\"probability\" + 0.005*\"node\" + 0.005*\"size\" + 0.004*\"threshold\" + 0.004*\"training\" + 0.004*\"proof\" + 0.004*\"kernel\" + 0.003*\"polynomial\" + 0.003*\"complexity\" + 0.003*\"xi\" + 0.003*\"theory\" + 0.003*\"consider\" + 0.003*\"machine\" + 0.003*\"defined\"\n",
      "\n",
      "Topic #8:\n",
      "0.011*\"state\" + 0.010*\"neuron\" + 0.010*\"dynamic\" + 0.009*\"pattern\" + 0.006*\"memory\" + 0.006*\"control\" + 0.005*\"equation\" + 0.005*\"attractor\" + 0.004*\"activity\" + 0.004*\"phase\" + 0.004*\"neural\" + 0.003*\"signal\" + 0.003*\"matrix\" + 0.003*\"motor\" + 0.003*\"oscillator\" + 0.003*\"movement\" + 0.003*\"fixed_point\" + 0.003*\"behavior\" + 0.003*\"trajectory\" + 0.003*\"connection\"\n",
      "\n",
      "Topic #9:\n",
      "0.009*\"stimulus\" + 0.009*\"visual\" + 0.009*\"motion\" + 0.009*\"signal\" + 0.008*\"response\" + 0.007*\"image\" + 0.007*\"unit\" + 0.007*\"filter\" + 0.006*\"cell\" + 0.006*\"direction\" + 0.005*\"map\" + 0.005*\"spatial\" + 0.004*\"orientation\" + 0.004*\"neuron\" + 0.004*\"receptive_field\" + 0.004*\"location\" + 0.004*\"pattern\" + 0.004*\"noise\" + 0.004*\"representation\" + 0.003*\"component\"\n",
      "\n",
      "Topic #10:\n",
      "0.019*\"unit\" + 0.014*\"state\" + 0.012*\"training\" + 0.009*\"sequence\" + 0.007*\"hidden_unit\" + 0.007*\"recurrent\" + 0.006*\"architecture\" + 0.006*\"layer\" + 0.006*\"net\" + 0.006*\"task\" + 0.005*\"activation\" + 0.005*\"node\" + 0.004*\"context\" + 0.004*\"rule\" + 0.004*\"trained\" + 0.004*\"pattern\" + 0.004*\"back_propagation\" + 0.004*\"step\" + 0.003*\"symbol\" + 0.003*\"hmm\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4jExj9SYRRyE",
    "outputId": "a771013f-ea53-4171-df63-2dac9bf33b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -1.0530915936779408\n"
     ]
    }
   ],
   "source": [
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic coherence is a complex topic in its own and it can be used to measure the\n",
    "quality of topic models to some extent. Typically, a set of statements is said to be\n",
    "coherent if they support each other. Topic models are unsupervised learning based\n",
    "models that are trained on unstructured text data, making it difficult to measure the\n",
    "quality of outputs. \n",
    "\n",
    "Refer to Text Analytics with Python 2nd Edition for more detail on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "azEdB08qRX4z",
    "outputId": "4c483402-3aa5-4892-86f5-40d548138beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('distribution', 0.007), ('training', 0.007), ('noise', 0.006), ('estimate', 0.005), ('vector', 0.005), ('equation', 0.005), ('approximation', 0.004), ('gaussian', 0.004), ('sample', 0.004), ('prediction', 0.004), ('prior', 0.004), ('density', 0.004), ('linear', 0.004), ('variance', 0.004), ('rate', 0.004), ('average', 0.004), ('matrix', 0.004), ('optimal', 0.003), ('solution', 0.003), ('probability', 0.003)]\n",
      "\n",
      "Topic #2:\n",
      "[('stimulus', 0.009), ('visual', 0.009), ('motion', 0.009), ('signal', 0.009), ('response', 0.008), ('image', 0.007), ('unit', 0.007), ('filter', 0.007), ('cell', 0.006), ('direction', 0.006), ('map', 0.005), ('spatial', 0.005), ('orientation', 0.004), ('neuron', 0.004), ('receptive_field', 0.004), ('location', 0.004), ('pattern', 0.004), ('noise', 0.004), ('representation', 0.004), ('component', 0.003)]\n",
      "\n",
      "Topic #3:\n",
      "[('neuron', 0.022), ('cell', 0.017), ('circuit', 0.009), ('response', 0.007), ('current', 0.007), ('synaptic', 0.006), ('spike', 0.006), ('voltage', 0.006), ('activity', 0.005), ('pattern', 0.005), ('firing', 0.004), ('chip', 0.004), ('synapsis', 0.004), ('connection', 0.004), ('signal', 0.004), ('neural', 0.004), ('stimulus', 0.004), ('layer', 0.004), ('effect', 0.004), ('cortical', 0.004)]\n",
      "\n",
      "Topic #4:\n",
      "[('training', 0.014), ('feature', 0.01), ('word', 0.01), ('classifier', 0.009), ('classification', 0.009), ('recognition', 0.009), ('pattern', 0.008), ('class', 0.007), ('trained', 0.006), ('task', 0.005), ('speech', 0.005), ('test', 0.004), ('unit', 0.004), ('training_set', 0.004), ('character', 0.004), ('experiment', 0.004), ('rule', 0.004), ('face', 0.004), ('representation', 0.004), ('layer', 0.003)]\n",
      "\n",
      "Topic #5:\n",
      "[('class', 0.01), ('let', 0.007), ('vector', 0.006), ('bound', 0.006), ('theorem', 0.006), ('linear', 0.005), ('probability', 0.005), ('node', 0.005), ('size', 0.005), ('threshold', 0.004), ('training', 0.004), ('proof', 0.004), ('kernel', 0.004), ('polynomial', 0.003), ('complexity', 0.003), ('xi', 0.003), ('theory', 0.003), ('consider', 0.003), ('machine', 0.003), ('defined', 0.003)]\n",
      "\n",
      "Topic #6:\n",
      "[('unit', 0.011), ('structure', 0.009), ('variable', 0.008), ('node', 0.007), ('representation', 0.007), ('tree', 0.006), ('vector', 0.006), ('cluster', 0.006), ('image', 0.005), ('probability', 0.004), ('pattern', 0.004), ('clustering', 0.004), ('level', 0.004), ('feature', 0.004), ('graph', 0.004), ('object', 0.004), ('mixture', 0.003), ('distribution', 0.003), ('layer', 0.003), ('local', 0.003)]\n",
      "\n",
      "Topic #7:\n",
      "[('image', 0.022), ('object', 0.009), ('feature', 0.008), ('vector', 0.007), ('bit', 0.004), ('pixel', 0.004), ('view', 0.004), ('chip', 0.004), ('search', 0.004), ('processor', 0.004), ('constraint', 0.003), ('code', 0.003), ('region', 0.003), ('parallel', 0.003), ('distance', 0.003), ('solution', 0.003), ('matrix', 0.003), ('surface', 0.003), ('memory', 0.003), ('application', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('unit', 0.019), ('state', 0.014), ('training', 0.012), ('sequence', 0.009), ('hidden_unit', 0.007), ('recurrent', 0.007), ('architecture', 0.006), ('layer', 0.006), ('net', 0.006), ('task', 0.006), ('activation', 0.005), ('node', 0.005), ('context', 0.004), ('rule', 0.004), ('trained', 0.004), ('pattern', 0.004), ('back_propagation', 0.004), ('step', 0.004), ('symbol', 0.003), ('hmm', 0.003)]\n",
      "\n",
      "Topic #9:\n",
      "[('state', 0.023), ('action', 0.012), ('control', 0.011), ('policy', 0.007), ('step', 0.007), ('task', 0.006), ('reinforcement_learning', 0.006), ('optimal', 0.005), ('controller', 0.005), ('environment', 0.005), ('robot', 0.004), ('goal', 0.004), ('reward', 0.004), ('expert', 0.004), ('td', 0.003), ('agent', 0.003), ('local', 0.003), ('cost', 0.003), ('current', 0.003), ('probability', 0.003)]\n",
      "\n",
      "Topic #10:\n",
      "[('state', 0.011), ('neuron', 0.01), ('dynamic', 0.01), ('pattern', 0.009), ('memory', 0.006), ('control', 0.006), ('equation', 0.005), ('attractor', 0.005), ('activity', 0.004), ('phase', 0.004), ('neural', 0.004), ('signal', 0.003), ('matrix', 0.003), ('motor', 0.003), ('oscillator', 0.003), ('movement', 0.003), ('fixed_point', 0.003), ('behavior', 0.003), ('trajectory', 0.003), ('connection', 0.003)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt, 3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "EAkgJa3XRZ3m",
    "outputId": "d6216f06-71d1-463c-c7d6-9e825e6d20b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['distribution', 'training', 'noise', 'estimate', 'vector', 'equation', 'approximation', 'gaussian', 'sample', 'prediction', 'prior', 'density', 'linear', 'variance', 'rate', 'average', 'matrix', 'optimal', 'solution', 'probability']\n",
      "\n",
      "Topic #2:\n",
      "['stimulus', 'visual', 'motion', 'signal', 'response', 'image', 'unit', 'filter', 'cell', 'direction', 'map', 'spatial', 'orientation', 'neuron', 'receptive_field', 'location', 'pattern', 'noise', 'representation', 'component']\n",
      "\n",
      "Topic #3:\n",
      "['neuron', 'cell', 'circuit', 'response', 'current', 'synaptic', 'spike', 'voltage', 'activity', 'pattern', 'firing', 'chip', 'synapsis', 'connection', 'signal', 'neural', 'stimulus', 'layer', 'effect', 'cortical']\n",
      "\n",
      "Topic #4:\n",
      "['training', 'feature', 'word', 'classifier', 'classification', 'recognition', 'pattern', 'class', 'trained', 'task', 'speech', 'test', 'unit', 'training_set', 'character', 'experiment', 'rule', 'face', 'representation', 'layer']\n",
      "\n",
      "Topic #5:\n",
      "['class', 'let', 'vector', 'bound', 'theorem', 'linear', 'probability', 'node', 'size', 'threshold', 'training', 'proof', 'kernel', 'polynomial', 'complexity', 'xi', 'theory', 'consider', 'machine', 'defined']\n",
      "\n",
      "Topic #6:\n",
      "['unit', 'structure', 'variable', 'node', 'representation', 'tree', 'vector', 'cluster', 'image', 'probability', 'pattern', 'clustering', 'level', 'feature', 'graph', 'object', 'mixture', 'distribution', 'layer', 'local']\n",
      "\n",
      "Topic #7:\n",
      "['image', 'object', 'feature', 'vector', 'bit', 'pixel', 'view', 'chip', 'search', 'processor', 'constraint', 'code', 'region', 'parallel', 'distance', 'solution', 'matrix', 'surface', 'memory', 'application']\n",
      "\n",
      "Topic #8:\n",
      "['unit', 'state', 'training', 'sequence', 'hidden_unit', 'recurrent', 'architecture', 'layer', 'net', 'task', 'activation', 'node', 'context', 'rule', 'trained', 'pattern', 'back_propagation', 'step', 'symbol', 'hmm']\n",
      "\n",
      "Topic #9:\n",
      "['state', 'action', 'control', 'policy', 'step', 'task', 'reinforcement_learning', 'optimal', 'controller', 'environment', 'robot', 'goal', 'reward', 'expert', 'td', 'agent', 'local', 'cost', 'current', 'probability']\n",
      "\n",
      "Topic #10:\n",
      "['state', 'neuron', 'dynamic', 'pattern', 'memory', 'control', 'equation', 'attractor', 'activity', 'phase', 'neural', 'signal', 'matrix', 'motor', 'oscillator', 'movement', 'fixed_point', 'behavior', 'trajectory', 'connection']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating topic model quality\n",
    "\n",
    "We can use perplexity and coherence scores as measures to evaluate the topic\n",
    "model. Typically, lower the perplexity, the better the model. Similarly, the lower the\n",
    "UMass score and the higher the Cv score in coherence, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WkOZQdZERbzG",
    "outputId": "8bf20ba0-8953-47d0-cc29-486cd545b93f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.46898489232942786\n",
      "Avg. Coherence Score (UMass): -1.053091593677941\n",
      "Model Perplexity: -7.794018299254993\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams,\n",
    "                                                      dictionary=dictionary, \n",
    "                                                      coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams,\n",
    "                                                         dictionary=dictionary, \n",
    "                                                         coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Models with MALLET\n",
    "\n",
    "The MALLET framework is a Java-based package for statistical natural language\n",
    "processing, document classification, clustering, topic modeling, information extraction,\n",
    "and other machine learning applications to text. MALLET stands for MAchine Learning\n",
    "for LanguagE Toolkit. It was developed by Andrew McCallum along with several people\n",
    "at the University of Massachusetts Amherst. The MALLET topic modeling toolkit\n",
    "contains efficient, sampling-based implementations of Latent Dirichlet Allocation,\n",
    "Pachinko Allocation, and Hierarchical LDA. To use MALLET’s capabilities, we need to\n",
    "download the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "NSRYjYP7VXPz",
    "outputId": "0583e711-2ca4-4c75-e3d7-59e89b24bc13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-04 20:34:12--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
      "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
      "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16184794 (15M) [application/zip]\n",
      "Saving to: ‘mallet-2.0.8.zip’\n",
      "\n",
      "mallet-2.0.8.zip    100%[===================>]  15.43M  13.6MB/s    in 1.1s    \n",
      "\n",
      "2019-08-04 20:34:14 (13.6 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "!unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "s0J3x_IcVu8z",
    "outputId": "469ca2d7-5295-4eb1-c586-7c95505ba213"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus, \n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n",
    "                                              iterations=500, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HQcf70_0WHDc",
    "outputId": "0cb8d94d-2581-46b3-cf87-c413a28df3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.518784549363429\n",
      "Avg. Coherence Score (UMass): -1.071309554631297\n",
      "Model Perplexity: -8.50105\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams,\n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams,\n",
    "                                                                dictionary=dictionary,  \n",
    "                                                                coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.50105\n",
    "perplexity = -8.50105\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Tuning: Finding the optimal number of topics\n",
    "\n",
    "Finding the optimal number of topics in a topic model is tough, given that it is like a\n",
    "model hyperparameter that you always have to set before training the model. We can\n",
    "use an iterative approach and build several models with differing numbers of topics and\n",
    "select the one that has the highest coherence score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYeyeNmRWy4m"
   },
   "outputs": [],
   "source": [
    "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
    "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
    "                                    cpus=1):\n",
    "    \n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm.tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n",
    "                                                            num_topics=topic_nums, id2word=dictionary,\n",
    "                                                            iterations=500, workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus, \n",
    "                                                                     texts=texts, dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "8vgKu5RCXHrv",
    "outputId": "304f9b00-925f-496a-c375-8a1407b13f13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/29 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "100%|██████████| 29/29 [1:39:20<00:00, 252.57s/it]\n"
     ]
    }
   ],
   "source": [
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
    "                                                               dictionary=dictionary, start_topic_count=2,\n",
    "                                                               end_topic_count=30, step=1, cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "EeQIjHsOXPvY",
    "outputId": "0716e17e-5381-4b7b-b39b-b00a463c1e0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.5467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0.5409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "19                21           0.5467\n",
       "27                29           0.5429\n",
       "15                17           0.5412\n",
       "23                25           0.5409\n",
       "25                27           0.5400\n",
       "12                14           0.5376\n",
       "13                15           0.5340\n",
       "18                20           0.5331\n",
       "20                22           0.5330\n",
       "24                26           0.5329"
      ]
     },
     "execution_count": 215,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "UBSRO_VqYjif",
    "outputId": "064e3cf4-ab1c-4c73-b04c-4d9cf3c67cac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy8AAAFzCAYAAAA3/jaVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2, 31, 1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_ax, y_ax, c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "xl = plt.xlabel('Number of Topics')\n",
    "yl = plt.ylabel('Coherence Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the optimal number of topics as 20, based on our intuition. We can retrieve the best model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YtPwVFdrYlxO",
    "outputId": "f74d30a1-0161-4b1b-9578-05cd5bcfbc7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 220,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sQj6L5w4lWXa",
    "outputId": "70ae4b4e-88be-497f-c5bd-595a11b36d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['image', 'object', 'feature', 'pixel', 'view', 'face', 'region', 'visual', 'representation', 'surface', 'edge', 'location', 'shape', 'recognition', 'scale', 'contour', 'local', 'part', 'scene', 'vision']\n",
      "\n",
      "Topic #2:\n",
      "['equation', 'rate', 'convergence', 'gradient', 'vector', 'optimal', 'iteration', 'eq', 'update', 'constant', 'line', 'gradient_descent', 'rule', 'derivative', 'step', 'minimum', 'approximation', 'change', 'noise', 'adaptive']\n",
      "\n",
      "Topic #3:\n",
      "['state', 'action', 'step', 'policy', 'control', 'reinforcement_learning', 'environment', 'optimal', 'task', 'goal', 'reward', 'td', 'agent', 'current', 'machine', 'transition', 'cost', 'reinforcement', 'rl', 'update']\n",
      "\n",
      "Topic #4:\n",
      "['training', 'class', 'classification', 'classifier', 'training_set', 'pattern', 'feature', 'test', 'machine', 'sample', 'test_set', 'size', 'trained', 'kernel', 'ensemble', 'table', 'nearest_neighbor', 'margin', 'pruning', 'error_rate']\n",
      "\n",
      "Topic #5:\n",
      "['task', 'target', 'rate', 'test', 'curve', 'experiment', 'training', 'effect', 'random', 'trial', 'generalization', 'search', 'instance', 'size', 'subject', 'average', 'bias', 'study', 'human', 'measure']\n",
      "\n",
      "Topic #6:\n",
      "['solution', 'constraint', 'local', 'energy', 'linear', 'optimization', 'nonlinear', 'global', 'potential', 'optimal', 'find', 'minimum', 'temperature', 'criterion', 'principle', 'search', 'path', 'variable', 'design', 'maximum']\n",
      "\n",
      "Topic #7:\n",
      "['signal', 'noise', 'filter', 'source', 'frequency', 'channel', 'component', 'response', 'temporal', 'auditory', 'sound', 'detection', 'ica', 'phase', 'amplitude', 'correlation', 'light', 'eeg', 'linear', 'processing']\n",
      "\n",
      "Topic #8:\n",
      "['prediction', 'application', 'experiment', 'table', 'user', 'query', 'time_series', 'variable', 'sequence', 'type', 'block', 'predictor', 'modeling', 'future', 'technique', 'predictive', 'predict', 'series', 'predicted', 'protein']\n",
      "\n",
      "Topic #9:\n",
      "['dynamic', 'state', 'memory', 'pattern', 'equation', 'neuron', 'attractor', 'capacity', 'fixed_point', 'noise', 'phase', 'hopfield', 'teacher', 'theory', 'stable', 'student', 'matrix', 'delay', 'symmetric', 'behavior']\n",
      "\n",
      "Topic #10:\n",
      "['cell', 'response', 'stimulus', 'activity', 'visual', 'receptive_field', 'map', 'pattern', 'spatial', 'unit', 'orientation', 'cortical', 'layer', 'cortex', 'center', 'region', 'contrast', 'eye', 'area', 'neuron']\n",
      "\n",
      "Topic #11:\n",
      "['distribution', 'probability', 'prior', 'variable', 'gaussian', 'bayesian', 'log', 'density', 'approximation', 'entropy', 'posterior', 'probabilistic', 'likelihood', 'sample', 'stochastic', 'mean_field', 'hidden', 'evidence', 'exp', 'probability_distribution']\n",
      "\n",
      "Topic #12:\n",
      "['vector', 'matrix', 'distance', 'component', 'code', 'transformation', 'linear', 'dimensional', 'map', 'dimension', 'mapping', 'representation', 'basis', 'pca', 'structure', 'projection', 'coding', 'principal_component', 'direction', 'coordinate']\n",
      "\n",
      "Topic #13:\n",
      "['neuron', 'cell', 'spike', 'synaptic', 'activity', 'firing', 'response', 'synapsis', 'neural', 'current', 'threshold', 'pattern', 'et_al', 'constant', 'stimulus', 'oscillator', 'neuronal', 'firing_rate', 'level', 'effect']\n",
      "\n",
      "Topic #14:\n",
      "['word', 'recognition', 'speech', 'training', 'character', 'sequence', 'hmm', 'context', 'feature', 'frame', 'letter', 'speaker', 'state', 'trained', 'speech_recognition', 'phoneme', 'digit', 'segmentation', 'mlp', 'hybrid']\n",
      "\n",
      "Topic #15:\n",
      "['circuit', 'chip', 'current', 'analog', 'voltage', 'neuron', 'bit', 'implementation', 'processor', 'design', 'parallel', 'operation', 'device', 'neural', 'digital', 'computation', 'array', 'synapse', 'hardware', 'implemented']\n",
      "\n",
      "Topic #16:\n",
      "['estimate', 'estimation', 'mixture', 'cluster', 'regression', 'variance', 'expert', 'clustering', 'sample', 'kernel', 'step', 'estimator', 'gaussian', 'rbf', 'noise', 'estimated', 'em', 'linear', 'density', 'nonlinear']\n",
      "\n",
      "Topic #17:\n",
      "['unit', 'layer', 'training', 'hidden_unit', 'net', 'pattern', 'architecture', 'activation', 'trained', 'recurrent', 'back_propagation', 'connection', 'task', 'hidden_layer', 'module', 'hidden', 'backpropagation', 'learn', 'simulation', 'step']\n",
      "\n",
      "Topic #18:\n",
      "['bound', 'theorem', 'class', 'size', 'threshold', 'complexity', 'proof', 'loss', 'polynomial', 'linear', 'approximation', 'probability', 'assume', 'theory', 'definition', 'xi', 'defined', 'constant', 'bounded', 'define']\n",
      "\n",
      "Topic #19:\n",
      "['control', 'motion', 'position', 'trajectory', 'velocity', 'movement', 'direction', 'motor', 'target', 'controller', 'hand', 'field', 'dynamic', 'feedback', 'forward', 'robot', 'change', 'arm', 'location', 'head']\n",
      "\n",
      "Topic #20:\n",
      "['node', 'rule', 'structure', 'representation', 'tree', 'level', 'graph', 'symbol', 'sequence', 'string', 'language', 'connectionist', 'similarity', 'represented', 'part', 'role', 'category', 'note', 'machine', 'item']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "                   for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing LDA Model topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "V-SpgKYRpHsA",
    "outputId": "82a342d4-0196-41c3-c5f4-66bfe24b2459"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>image</td>\n",
       "      <td>equation</td>\n",
       "      <td>state</td>\n",
       "      <td>training</td>\n",
       "      <td>task</td>\n",
       "      <td>solution</td>\n",
       "      <td>signal</td>\n",
       "      <td>prediction</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>cell</td>\n",
       "      <td>distribution</td>\n",
       "      <td>vector</td>\n",
       "      <td>neuron</td>\n",
       "      <td>word</td>\n",
       "      <td>circuit</td>\n",
       "      <td>estimate</td>\n",
       "      <td>unit</td>\n",
       "      <td>bound</td>\n",
       "      <td>control</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>object</td>\n",
       "      <td>rate</td>\n",
       "      <td>action</td>\n",
       "      <td>class</td>\n",
       "      <td>target</td>\n",
       "      <td>constraint</td>\n",
       "      <td>noise</td>\n",
       "      <td>application</td>\n",
       "      <td>state</td>\n",
       "      <td>response</td>\n",
       "      <td>probability</td>\n",
       "      <td>matrix</td>\n",
       "      <td>cell</td>\n",
       "      <td>recognition</td>\n",
       "      <td>chip</td>\n",
       "      <td>estimation</td>\n",
       "      <td>layer</td>\n",
       "      <td>theorem</td>\n",
       "      <td>motion</td>\n",
       "      <td>rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>feature</td>\n",
       "      <td>convergence</td>\n",
       "      <td>step</td>\n",
       "      <td>classification</td>\n",
       "      <td>rate</td>\n",
       "      <td>local</td>\n",
       "      <td>filter</td>\n",
       "      <td>experiment</td>\n",
       "      <td>memory</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>prior</td>\n",
       "      <td>distance</td>\n",
       "      <td>spike</td>\n",
       "      <td>speech</td>\n",
       "      <td>current</td>\n",
       "      <td>mixture</td>\n",
       "      <td>training</td>\n",
       "      <td>class</td>\n",
       "      <td>position</td>\n",
       "      <td>structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>pixel</td>\n",
       "      <td>gradient</td>\n",
       "      <td>policy</td>\n",
       "      <td>classifier</td>\n",
       "      <td>test</td>\n",
       "      <td>energy</td>\n",
       "      <td>source</td>\n",
       "      <td>table</td>\n",
       "      <td>pattern</td>\n",
       "      <td>activity</td>\n",
       "      <td>variable</td>\n",
       "      <td>component</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>training</td>\n",
       "      <td>analog</td>\n",
       "      <td>cluster</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>size</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>representation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>view</td>\n",
       "      <td>vector</td>\n",
       "      <td>control</td>\n",
       "      <td>training_set</td>\n",
       "      <td>curve</td>\n",
       "      <td>linear</td>\n",
       "      <td>frequency</td>\n",
       "      <td>user</td>\n",
       "      <td>equation</td>\n",
       "      <td>visual</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>code</td>\n",
       "      <td>activity</td>\n",
       "      <td>character</td>\n",
       "      <td>voltage</td>\n",
       "      <td>regression</td>\n",
       "      <td>net</td>\n",
       "      <td>threshold</td>\n",
       "      <td>velocity</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>face</td>\n",
       "      <td>optimal</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>pattern</td>\n",
       "      <td>experiment</td>\n",
       "      <td>optimization</td>\n",
       "      <td>channel</td>\n",
       "      <td>query</td>\n",
       "      <td>neuron</td>\n",
       "      <td>receptive_field</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>transformation</td>\n",
       "      <td>firing</td>\n",
       "      <td>sequence</td>\n",
       "      <td>neuron</td>\n",
       "      <td>variance</td>\n",
       "      <td>pattern</td>\n",
       "      <td>complexity</td>\n",
       "      <td>movement</td>\n",
       "      <td>level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>region</td>\n",
       "      <td>iteration</td>\n",
       "      <td>environment</td>\n",
       "      <td>feature</td>\n",
       "      <td>training</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>component</td>\n",
       "      <td>time_series</td>\n",
       "      <td>attractor</td>\n",
       "      <td>map</td>\n",
       "      <td>log</td>\n",
       "      <td>linear</td>\n",
       "      <td>response</td>\n",
       "      <td>hmm</td>\n",
       "      <td>bit</td>\n",
       "      <td>expert</td>\n",
       "      <td>architecture</td>\n",
       "      <td>proof</td>\n",
       "      <td>direction</td>\n",
       "      <td>graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>visual</td>\n",
       "      <td>eq</td>\n",
       "      <td>optimal</td>\n",
       "      <td>test</td>\n",
       "      <td>effect</td>\n",
       "      <td>global</td>\n",
       "      <td>response</td>\n",
       "      <td>variable</td>\n",
       "      <td>capacity</td>\n",
       "      <td>pattern</td>\n",
       "      <td>density</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>context</td>\n",
       "      <td>implementation</td>\n",
       "      <td>clustering</td>\n",
       "      <td>activation</td>\n",
       "      <td>loss</td>\n",
       "      <td>motor</td>\n",
       "      <td>symbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>representation</td>\n",
       "      <td>update</td>\n",
       "      <td>task</td>\n",
       "      <td>machine</td>\n",
       "      <td>random</td>\n",
       "      <td>potential</td>\n",
       "      <td>temporal</td>\n",
       "      <td>sequence</td>\n",
       "      <td>fixed_point</td>\n",
       "      <td>spatial</td>\n",
       "      <td>approximation</td>\n",
       "      <td>map</td>\n",
       "      <td>neural</td>\n",
       "      <td>feature</td>\n",
       "      <td>processor</td>\n",
       "      <td>sample</td>\n",
       "      <td>trained</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>target</td>\n",
       "      <td>sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>surface</td>\n",
       "      <td>constant</td>\n",
       "      <td>goal</td>\n",
       "      <td>sample</td>\n",
       "      <td>trial</td>\n",
       "      <td>optimal</td>\n",
       "      <td>auditory</td>\n",
       "      <td>type</td>\n",
       "      <td>noise</td>\n",
       "      <td>unit</td>\n",
       "      <td>entropy</td>\n",
       "      <td>dimension</td>\n",
       "      <td>current</td>\n",
       "      <td>frame</td>\n",
       "      <td>design</td>\n",
       "      <td>kernel</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>linear</td>\n",
       "      <td>controller</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>edge</td>\n",
       "      <td>line</td>\n",
       "      <td>reward</td>\n",
       "      <td>test_set</td>\n",
       "      <td>generalization</td>\n",
       "      <td>find</td>\n",
       "      <td>sound</td>\n",
       "      <td>block</td>\n",
       "      <td>phase</td>\n",
       "      <td>orientation</td>\n",
       "      <td>posterior</td>\n",
       "      <td>mapping</td>\n",
       "      <td>threshold</td>\n",
       "      <td>letter</td>\n",
       "      <td>parallel</td>\n",
       "      <td>step</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>approximation</td>\n",
       "      <td>hand</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>location</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>td</td>\n",
       "      <td>size</td>\n",
       "      <td>search</td>\n",
       "      <td>minimum</td>\n",
       "      <td>detection</td>\n",
       "      <td>predictor</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>cortical</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>representation</td>\n",
       "      <td>pattern</td>\n",
       "      <td>speaker</td>\n",
       "      <td>operation</td>\n",
       "      <td>estimator</td>\n",
       "      <td>connection</td>\n",
       "      <td>probability</td>\n",
       "      <td>field</td>\n",
       "      <td>connectionist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>shape</td>\n",
       "      <td>rule</td>\n",
       "      <td>agent</td>\n",
       "      <td>trained</td>\n",
       "      <td>instance</td>\n",
       "      <td>temperature</td>\n",
       "      <td>ica</td>\n",
       "      <td>modeling</td>\n",
       "      <td>teacher</td>\n",
       "      <td>layer</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>basis</td>\n",
       "      <td>et_al</td>\n",
       "      <td>state</td>\n",
       "      <td>device</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>task</td>\n",
       "      <td>assume</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>recognition</td>\n",
       "      <td>derivative</td>\n",
       "      <td>current</td>\n",
       "      <td>kernel</td>\n",
       "      <td>size</td>\n",
       "      <td>criterion</td>\n",
       "      <td>phase</td>\n",
       "      <td>future</td>\n",
       "      <td>theory</td>\n",
       "      <td>cortex</td>\n",
       "      <td>sample</td>\n",
       "      <td>pca</td>\n",
       "      <td>constant</td>\n",
       "      <td>trained</td>\n",
       "      <td>neural</td>\n",
       "      <td>rbf</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>theory</td>\n",
       "      <td>feedback</td>\n",
       "      <td>represented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>scale</td>\n",
       "      <td>step</td>\n",
       "      <td>machine</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>subject</td>\n",
       "      <td>principle</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>technique</td>\n",
       "      <td>stable</td>\n",
       "      <td>center</td>\n",
       "      <td>stochastic</td>\n",
       "      <td>structure</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>speech_recognition</td>\n",
       "      <td>digital</td>\n",
       "      <td>noise</td>\n",
       "      <td>module</td>\n",
       "      <td>definition</td>\n",
       "      <td>forward</td>\n",
       "      <td>part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>contour</td>\n",
       "      <td>minimum</td>\n",
       "      <td>transition</td>\n",
       "      <td>table</td>\n",
       "      <td>average</td>\n",
       "      <td>search</td>\n",
       "      <td>correlation</td>\n",
       "      <td>predictive</td>\n",
       "      <td>student</td>\n",
       "      <td>region</td>\n",
       "      <td>mean_field</td>\n",
       "      <td>projection</td>\n",
       "      <td>oscillator</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>computation</td>\n",
       "      <td>estimated</td>\n",
       "      <td>hidden</td>\n",
       "      <td>xi</td>\n",
       "      <td>robot</td>\n",
       "      <td>role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>local</td>\n",
       "      <td>approximation</td>\n",
       "      <td>cost</td>\n",
       "      <td>nearest_neighbor</td>\n",
       "      <td>bias</td>\n",
       "      <td>path</td>\n",
       "      <td>light</td>\n",
       "      <td>predict</td>\n",
       "      <td>matrix</td>\n",
       "      <td>contrast</td>\n",
       "      <td>hidden</td>\n",
       "      <td>coding</td>\n",
       "      <td>neuronal</td>\n",
       "      <td>digit</td>\n",
       "      <td>array</td>\n",
       "      <td>em</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>defined</td>\n",
       "      <td>change</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>part</td>\n",
       "      <td>change</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>margin</td>\n",
       "      <td>study</td>\n",
       "      <td>variable</td>\n",
       "      <td>eeg</td>\n",
       "      <td>series</td>\n",
       "      <td>delay</td>\n",
       "      <td>eye</td>\n",
       "      <td>evidence</td>\n",
       "      <td>principal_component</td>\n",
       "      <td>firing_rate</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>synapse</td>\n",
       "      <td>linear</td>\n",
       "      <td>learn</td>\n",
       "      <td>constant</td>\n",
       "      <td>arm</td>\n",
       "      <td>note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>scene</td>\n",
       "      <td>noise</td>\n",
       "      <td>rl</td>\n",
       "      <td>pruning</td>\n",
       "      <td>human</td>\n",
       "      <td>design</td>\n",
       "      <td>linear</td>\n",
       "      <td>predicted</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>area</td>\n",
       "      <td>exp</td>\n",
       "      <td>direction</td>\n",
       "      <td>level</td>\n",
       "      <td>mlp</td>\n",
       "      <td>hardware</td>\n",
       "      <td>density</td>\n",
       "      <td>simulation</td>\n",
       "      <td>bounded</td>\n",
       "      <td>location</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>vision</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>update</td>\n",
       "      <td>error_rate</td>\n",
       "      <td>measure</td>\n",
       "      <td>maximum</td>\n",
       "      <td>processing</td>\n",
       "      <td>protein</td>\n",
       "      <td>behavior</td>\n",
       "      <td>neuron</td>\n",
       "      <td>probability_distribution</td>\n",
       "      <td>coordinate</td>\n",
       "      <td>effect</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>implemented</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>step</td>\n",
       "      <td>define</td>\n",
       "      <td>head</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Topic 1           Topic 2  ...    Topic 19        Topic 20\n",
       "Term1            image          equation  ...     control            node\n",
       "Term2           object              rate  ...      motion            rule\n",
       "Term3          feature       convergence  ...    position       structure\n",
       "Term4            pixel          gradient  ...  trajectory  representation\n",
       "Term5             view            vector  ...    velocity            tree\n",
       "Term6             face           optimal  ...    movement           level\n",
       "Term7           region         iteration  ...   direction           graph\n",
       "Term8           visual                eq  ...       motor          symbol\n",
       "Term9   representation            update  ...      target        sequence\n",
       "Term10         surface          constant  ...  controller          string\n",
       "Term11            edge              line  ...        hand        language\n",
       "Term12        location  gradient_descent  ...       field   connectionist\n",
       "Term13           shape              rule  ...     dynamic      similarity\n",
       "Term14     recognition        derivative  ...    feedback     represented\n",
       "Term15           scale              step  ...     forward            part\n",
       "Term16         contour           minimum  ...       robot            role\n",
       "Term17           local     approximation  ...      change        category\n",
       "Term18            part            change  ...         arm            note\n",
       "Term19           scene             noise  ...    location         machine\n",
       "Term20          vision          adaptive  ...        head            item\n",
       "\n",
       "[20 rows x 20 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "MvyOKlu4p7UG",
    "outputId": "397ca3f1-3700-4518-fa10-92ac2b98a2ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>image, object, feature, pixel, view, face, region, visual, representation, surface, edge, location, shape, recognition, scale, contour, local, part, scene, vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>equation, rate, convergence, gradient, vector, optimal, iteration, eq, update, constant, line, gradient_descent, rule, derivative, step, minimum, approximation, change, noise, adaptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>state, action, step, policy, control, reinforcement_learning, environment, optimal, task, goal, reward, td, agent, current, machine, transition, cost, reinforcement, rl, update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>training, class, classification, classifier, training_set, pattern, feature, test, machine, sample, test_set, size, trained, kernel, ensemble, table, nearest_neighbor, margin, pruning, error_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>task, target, rate, test, curve, experiment, training, effect, random, trial, generalization, search, instance, size, subject, average, bias, study, human, measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>solution, constraint, local, energy, linear, optimization, nonlinear, global, potential, optimal, find, minimum, temperature, criterion, principle, search, path, variable, design, maximum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>signal, noise, filter, source, frequency, channel, component, response, temporal, auditory, sound, detection, ica, phase, amplitude, correlation, light, eeg, linear, processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>prediction, application, experiment, table, user, query, time_series, variable, sequence, type, block, predictor, modeling, future, technique, predictive, predict, series, predicted, protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>dynamic, state, memory, pattern, equation, neuron, attractor, capacity, fixed_point, noise, phase, hopfield, teacher, theory, stable, student, matrix, delay, symmetric, behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>cell, response, stimulus, activity, visual, receptive_field, map, pattern, spatial, unit, orientation, cortical, layer, cortex, center, region, contrast, eye, area, neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>distribution, probability, prior, variable, gaussian, bayesian, log, density, approximation, entropy, posterior, probabilistic, likelihood, sample, stochastic, mean_field, hidden, evidence, exp, probability_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>vector, matrix, distance, component, code, transformation, linear, dimensional, map, dimension, mapping, representation, basis, pca, structure, projection, coding, principal_component, direction, coordinate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>neuron, cell, spike, synaptic, activity, firing, response, synapsis, neural, current, threshold, pattern, et_al, constant, stimulus, oscillator, neuronal, firing_rate, level, effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>word, recognition, speech, training, character, sequence, hmm, context, feature, frame, letter, speaker, state, trained, speech_recognition, phoneme, digit, segmentation, mlp, hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>circuit, chip, current, analog, voltage, neuron, bit, implementation, processor, design, parallel, operation, device, neural, digital, computation, array, synapse, hardware, implemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>estimate, estimation, mixture, cluster, regression, variance, expert, clustering, sample, kernel, step, estimator, gaussian, rbf, noise, estimated, em, linear, density, nonlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>unit, layer, training, hidden_unit, net, pattern, architecture, activation, trained, recurrent, back_propagation, connection, task, hidden_layer, module, hidden, backpropagation, learn, simulation, step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>bound, theorem, class, size, threshold, complexity, proof, loss, polynomial, linear, approximation, probability, assume, theory, definition, xi, defined, constant, bounded, define</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>control, motion, position, trajectory, velocity, movement, direction, motor, target, controller, hand, field, dynamic, feedback, forward, robot, change, arm, location, head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>node, rule, structure, representation, tree, level, graph, symbol, sequence, string, language, connectionist, similarity, represented, part, role, category, note, machine, item</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                     Terms per Topic\n",
       "Topic1   image, object, feature, pixel, view, face, region, visual, representation, surface, edge, location, shape, recognition, scale, contour, local, part, scene, vision                                                         \n",
       "Topic2   equation, rate, convergence, gradient, vector, optimal, iteration, eq, update, constant, line, gradient_descent, rule, derivative, step, minimum, approximation, change, noise, adaptive                                   \n",
       "Topic3   state, action, step, policy, control, reinforcement_learning, environment, optimal, task, goal, reward, td, agent, current, machine, transition, cost, reinforcement, rl, update                                           \n",
       "Topic4   training, class, classification, classifier, training_set, pattern, feature, test, machine, sample, test_set, size, trained, kernel, ensemble, table, nearest_neighbor, margin, pruning, error_rate                        \n",
       "Topic5   task, target, rate, test, curve, experiment, training, effect, random, trial, generalization, search, instance, size, subject, average, bias, study, human, measure                                                        \n",
       "Topic6   solution, constraint, local, energy, linear, optimization, nonlinear, global, potential, optimal, find, minimum, temperature, criterion, principle, search, path, variable, design, maximum                                \n",
       "Topic7   signal, noise, filter, source, frequency, channel, component, response, temporal, auditory, sound, detection, ica, phase, amplitude, correlation, light, eeg, linear, processing                                           \n",
       "Topic8   prediction, application, experiment, table, user, query, time_series, variable, sequence, type, block, predictor, modeling, future, technique, predictive, predict, series, predicted, protein                             \n",
       "Topic9   dynamic, state, memory, pattern, equation, neuron, attractor, capacity, fixed_point, noise, phase, hopfield, teacher, theory, stable, student, matrix, delay, symmetric, behavior                                          \n",
       "Topic10  cell, response, stimulus, activity, visual, receptive_field, map, pattern, spatial, unit, orientation, cortical, layer, cortex, center, region, contrast, eye, area, neuron                                                \n",
       "Topic11  distribution, probability, prior, variable, gaussian, bayesian, log, density, approximation, entropy, posterior, probabilistic, likelihood, sample, stochastic, mean_field, hidden, evidence, exp, probability_distribution\n",
       "Topic12  vector, matrix, distance, component, code, transformation, linear, dimensional, map, dimension, mapping, representation, basis, pca, structure, projection, coding, principal_component, direction, coordinate             \n",
       "Topic13  neuron, cell, spike, synaptic, activity, firing, response, synapsis, neural, current, threshold, pattern, et_al, constant, stimulus, oscillator, neuronal, firing_rate, level, effect                                      \n",
       "Topic14  word, recognition, speech, training, character, sequence, hmm, context, feature, frame, letter, speaker, state, trained, speech_recognition, phoneme, digit, segmentation, mlp, hybrid                                     \n",
       "Topic15  circuit, chip, current, analog, voltage, neuron, bit, implementation, processor, design, parallel, operation, device, neural, digital, computation, array, synapse, hardware, implemented                                  \n",
       "Topic16  estimate, estimation, mixture, cluster, regression, variance, expert, clustering, sample, kernel, step, estimator, gaussian, rbf, noise, estimated, em, linear, density, nonlinear                                         \n",
       "Topic17  unit, layer, training, hidden_unit, net, pattern, architecture, activation, trained, recurrent, back_propagation, connection, task, hidden_layer, module, hidden, backpropagation, learn, simulation, step                 \n",
       "Topic18  bound, theorem, class, size, threshold, complexity, proof, loss, polynomial, linear, approximation, probability, assume, theory, definition, xi, defined, constant, bounded, define                                        \n",
       "Topic19  control, motion, position, trajectory, velocity, movement, direction, motor, target, controller, hand, field, dynamic, feedback, forward, robot, change, arm, location, head                                               \n",
       "Topic20  node, rule, structure, representation, tree, level, graph, symbol, sequence, string, language, connectionist, similarity, represented, part, role, category, note, machine, item                                           "
      ]
     },
     "execution_count": 223,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
    "                              for topic in topics],\n",
    "                         columns = ['Terms per Topic'],\n",
    "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
    "                         )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Topic Model Results\n",
    "\n",
    "An interesting point to remember is, given a corpus of documents (in the form of\n",
    "features, e.g., Bag of Words) and a trained topic model, you can predict the distribution of\n",
    "topics in each document (research paper in this case).\n",
    "\n",
    "We can now get the most dominant topic per research paper with some intelligent\n",
    "sorting and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "bXv0NRCXum-I",
    "outputId": "275a2291-ec64-4d54-8872-194f4430b254"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "tm_results = best_lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "WjEHWhVGuuG5",
    "outputId": "c97793ac-fa5a-49a4-b2b5-68ea75b9edf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18, 0.1888297872340426),\n",
       " (12, 0.44786386676321494),\n",
       " (5, 0.24530052681992331),\n",
       " (2, 0.5155421056564298),\n",
       " (8, 0.3266178266178266)]"
      ]
     },
     "execution_count": 225,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
    "                     for topics in tm_results]\n",
    "corpus_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFmddPmQuyXS"
   },
   "outputs": [],
   "source": [
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(papers))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Paper'] = papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dominant Topics Distribution Across Corpus\n",
    "\n",
    "The first thing we can do is look at the overall distribution of each topic across the corpus\n",
    "of research papers. Mainly we want to determine the total number of papers and the\n",
    "total percentage of papers where each of the 20 topics was the most dominant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856
    },
    "colab_type": "code",
    "id": "J95k1tvdu1yP",
    "outputId": "575dca8e-0066-48a8-c4fd-f8330b0e2064"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/generic.py:1315: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>% Total Docs</th>\n",
       "      <th>Topic Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>6.90</td>\n",
       "      <td>image, object, feature, pixel, view, face, region, visual, representation, surface, edge, location, shape, recognition, scale, contour, local, part, scene, vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>4.31</td>\n",
       "      <td>equation, rate, convergence, gradient, vector, optimal, iteration, eq, update, constant, line, gradient_descent, rule, derivative, step, minimum, approximation, change, noise, adaptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>6.21</td>\n",
       "      <td>state, action, step, policy, control, reinforcement_learning, environment, optimal, task, goal, reward, td, agent, current, machine, transition, cost, reinforcement, rl, update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>training, class, classification, classifier, training_set, pattern, feature, test, machine, sample, test_set, size, trained, kernel, ensemble, table, nearest_neighbor, margin, pruning, error_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>3.45</td>\n",
       "      <td>task, target, rate, test, curve, experiment, training, effect, random, trial, generalization, search, instance, size, subject, average, bias, study, human, measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>2.07</td>\n",
       "      <td>solution, constraint, local, energy, linear, optimization, nonlinear, global, potential, optimal, find, minimum, temperature, criterion, principle, search, path, variable, design, maximum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>4.25</td>\n",
       "      <td>signal, noise, filter, source, frequency, channel, component, response, temporal, auditory, sound, detection, ica, phase, amplitude, correlation, light, eeg, linear, processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>2.70</td>\n",
       "      <td>prediction, application, experiment, table, user, query, time_series, variable, sequence, type, block, predictor, modeling, future, technique, predictive, predict, series, predicted, protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>5.17</td>\n",
       "      <td>dynamic, state, memory, pattern, equation, neuron, attractor, capacity, fixed_point, noise, phase, hopfield, teacher, theory, stable, student, matrix, delay, symmetric, behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>116</td>\n",
       "      <td>6.67</td>\n",
       "      <td>cell, response, stimulus, activity, visual, receptive_field, map, pattern, spatial, unit, orientation, cortical, layer, cortex, center, region, contrast, eye, area, neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>114</td>\n",
       "      <td>6.55</td>\n",
       "      <td>distribution, probability, prior, variable, gaussian, bayesian, log, density, approximation, entropy, posterior, probabilistic, likelihood, sample, stochastic, mean_field, hidden, evidence, exp, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>3.51</td>\n",
       "      <td>vector, matrix, distance, component, code, transformation, linear, dimensional, map, dimension, mapping, representation, basis, pca, structure, projection, coding, principal_component, direction, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>121</td>\n",
       "      <td>6.95</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, firing, response, synapsis, neural, current, threshold, pattern, et_al, constant, stimulus, oscillator, neuronal, firing_rate, level, effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>89</td>\n",
       "      <td>5.11</td>\n",
       "      <td>word, recognition, speech, training, character, sequence, hmm, context, feature, frame, letter, speaker, state, trained, speech_recognition, phoneme, digit, segmentation, mlp, hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>110</td>\n",
       "      <td>6.32</td>\n",
       "      <td>circuit, chip, current, analog, voltage, neuron, bit, implementation, processor, design, parallel, operation, device, neural, digital, computation, array, synapse, hardware, implemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>96</td>\n",
       "      <td>5.52</td>\n",
       "      <td>estimate, estimation, mixture, cluster, regression, variance, expert, clustering, sample, kernel, step, estimator, gaussian, rbf, noise, estimated, em, linear, density, nonlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>76</td>\n",
       "      <td>4.37</td>\n",
       "      <td>unit, layer, training, hidden_unit, net, pattern, architecture, activation, trained, recurrent, back_propagation, connection, task, hidden_layer, module, hidden, backpropagation, learn, simulation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>109</td>\n",
       "      <td>6.26</td>\n",
       "      <td>bound, theorem, class, size, threshold, complexity, proof, loss, polynomial, linear, approximation, probability, assume, theory, definition, xi, defined, constant, bounded, define</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>75</td>\n",
       "      <td>4.31</td>\n",
       "      <td>control, motion, position, trajectory, velocity, movement, direction, motor, target, controller, hand, field, dynamic, feedback, forward, robot, change, arm, location, head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>4.31</td>\n",
       "      <td>node, rule, structure, representation, tree, level, graph, symbol, sequence, string, language, connectionist, similarity, represented, part, role, category, note, machine, item</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant Topic  ...                                                                                                                                                                                               Topic Desc\n",
       "0                1  ...                                       image, object, feature, pixel, view, face, region, visual, representation, surface, edge, location, shape, recognition, scale, contour, local, part, scene, vision\n",
       "1                2  ...                 equation, rate, convergence, gradient, vector, optimal, iteration, eq, update, constant, line, gradient_descent, rule, derivative, step, minimum, approximation, change, noise, adaptive\n",
       "2                3  ...                         state, action, step, policy, control, reinforcement_learning, environment, optimal, task, goal, reward, td, agent, current, machine, transition, cost, reinforcement, rl, update\n",
       "3                4  ...      training, class, classification, classifier, training_set, pattern, feature, test, machine, sample, test_set, size, trained, kernel, ensemble, table, nearest_neighbor, margin, pruning, error_rate\n",
       "4                5  ...                                      task, target, rate, test, curve, experiment, training, effect, random, trial, generalization, search, instance, size, subject, average, bias, study, human, measure\n",
       "5                6  ...              solution, constraint, local, energy, linear, optimization, nonlinear, global, potential, optimal, find, minimum, temperature, criterion, principle, search, path, variable, design, maximum\n",
       "6                7  ...                         signal, noise, filter, source, frequency, channel, component, response, temporal, auditory, sound, detection, ica, phase, amplitude, correlation, light, eeg, linear, processing\n",
       "7                8  ...           prediction, application, experiment, table, user, query, time_series, variable, sequence, type, block, predictor, modeling, future, technique, predictive, predict, series, predicted, protein\n",
       "8                9  ...                        dynamic, state, memory, pattern, equation, neuron, attractor, capacity, fixed_point, noise, phase, hopfield, teacher, theory, stable, student, matrix, delay, symmetric, behavior\n",
       "9               10  ...                              cell, response, stimulus, activity, visual, receptive_field, map, pattern, spatial, unit, orientation, cortical, layer, cortex, center, region, contrast, eye, area, neuron\n",
       "10              11  ...  distribution, probability, prior, variable, gaussian, bayesian, log, density, approximation, entropy, posterior, probabilistic, likelihood, sample, stochastic, mean_field, hidden, evidence, exp, p...\n",
       "11              12  ...  vector, matrix, distance, component, code, transformation, linear, dimensional, map, dimension, mapping, representation, basis, pca, structure, projection, coding, principal_component, direction, ...\n",
       "12              13  ...                    neuron, cell, spike, synaptic, activity, firing, response, synapsis, neural, current, threshold, pattern, et_al, constant, stimulus, oscillator, neuronal, firing_rate, level, effect\n",
       "13              14  ...                   word, recognition, speech, training, character, sequence, hmm, context, feature, frame, letter, speaker, state, trained, speech_recognition, phoneme, digit, segmentation, mlp, hybrid\n",
       "14              15  ...                circuit, chip, current, analog, voltage, neuron, bit, implementation, processor, design, parallel, operation, device, neural, digital, computation, array, synapse, hardware, implemented\n",
       "15              16  ...                       estimate, estimation, mixture, cluster, regression, variance, expert, clustering, sample, kernel, step, estimator, gaussian, rbf, noise, estimated, em, linear, density, nonlinear\n",
       "16              17  ...  unit, layer, training, hidden_unit, net, pattern, architecture, activation, trained, recurrent, back_propagation, connection, task, hidden_layer, module, hidden, backpropagation, learn, simulation...\n",
       "17              18  ...                      bound, theorem, class, size, threshold, complexity, proof, loss, polynomial, linear, approximation, probability, assume, theory, definition, xi, defined, constant, bounded, define\n",
       "18              19  ...                             control, motion, position, trajectory, velocity, movement, direction, motor, target, controller, hand, field, dynamic, feedback, forward, robot, change, arm, location, head\n",
       "19              20  ...                         node, rule, structure, representation, tree, level, graph, symbol, sequence, string, language, connectionist, similarity, represented, part, role, category, note, machine, item\n",
       "\n",
       "[20 rows x 4 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg({\n",
    "                                                'Dominant Topic': {\n",
    "                                                    'Doc Count': np.size,\n",
    "                                                    '% Total Docs': np.size }\n",
    "                                              })\n",
    "topic_stats_df = topic_stats_df['Dominant Topic'].reset_index()\n",
    "topic_stats_df['% Total Docs'] = topic_stats_df['% Total Docs'].apply(lambda row: round((row*100) / len(papers), 2))\n",
    "topic_stats_df['Topic Desc'] = [topics_df.iloc[t]['Terms per Topic'] for t in range(len(topic_stats_df))]\n",
    "topic_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dominant Topics in Specific Research Papers\n",
    "\n",
    "Another interesting perspective is to select specific papers, view the most dominant topic\n",
    "in each of those papers, and see if that makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pN45exiiu5sx",
    "outputId": "ff24e654-a34e-4fe2-8dae-ecc5d57c477c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>55.66</td>\n",
       "      <td>image, object, feature, pixel, view, face, region, visual, representation, surface, edge, location, shape, recognition, scale, contour, local, part, scene, vision</td>\n",
       "      <td>297 \\nA NETWORK FOR IMAGE SEGMENTATION \\nUSING COLOR \\nAnya Hurlbert and Tomaso Poggio \\nCenter for Biological Information Processing at Whitaker College \\nDepartment of Brain and Cognitive Scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1197</td>\n",
       "      <td>2</td>\n",
       "      <td>57.13</td>\n",
       "      <td>equation, rate, convergence, gradient, vector, optimal, iteration, eq, update, constant, line, gradient_descent, rule, derivative, step, minimum, approximation, change, noise, adaptive</td>\n",
       "      <td>Removing Noise in On-Line Search using \\nAdaptive Batch Sizes \\nGenevieve B. Orr \\nDepartment of Computer Science \\nWillamette University \\n900 State Street \\nSalem, Oregon 97301 \\ngorr)willamett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1158</td>\n",
       "      <td>3</td>\n",
       "      <td>74.16</td>\n",
       "      <td>state, action, step, policy, control, reinforcement_learning, environment, optimal, task, goal, reward, td, agent, current, machine, transition, cost, reinforcement, rl, update</td>\n",
       "      <td>Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039</td>\n",
       "      <td>4</td>\n",
       "      <td>66.83</td>\n",
       "      <td>training, class, classification, classifier, training_set, pattern, feature, test, machine, sample, test_set, size, trained, kernel, ensemble, table, nearest_neighbor, margin, pruning, error_rate</td>\n",
       "      <td>Boosting Decision Trees \\nHarris Drucker \\nAT&amp;T Bell Laboratories \\nHolmdel, New Jersey 07733 \\nCorinna Cortes \\nAT&amp;T Bell Laboratories \\nMurray Hill, New Jersey 07974 \\nAbstract \\nA new boosting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>583</td>\n",
       "      <td>5</td>\n",
       "      <td>48.27</td>\n",
       "      <td>task, target, rate, test, curve, experiment, training, effect, random, trial, generalization, search, instance, size, subject, average, bias, study, human, measure</td>\n",
       "      <td>A Knowledge-Based Model of Geometry Learning \\nGeoffrey Towell \\nSiemens Corporate Research \\n755 College Road East \\nPrinceton, NJ 08540 \\ntoweli @ learning. siemens. com \\nRichard Lehrer \\nEduca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1003</td>\n",
       "      <td>6</td>\n",
       "      <td>50.58</td>\n",
       "      <td>solution, constraint, local, energy, linear, optimization, nonlinear, global, potential, optimal, find, minimum, temperature, criterion, principle, search, path, variable, design, maximum</td>\n",
       "      <td>Softassign versus Softmax: Benchmarks \\nin Combinatorial Optimization \\nSteven Gold \\nDepartment of Computer Science \\nYale University \\nNew Haven, CT 06520-8285 \\nAnand Rangarajan \\nDept. of Diag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1314</td>\n",
       "      <td>7</td>\n",
       "      <td>56.34</td>\n",
       "      <td>signal, noise, filter, source, frequency, channel, component, response, temporal, auditory, sound, detection, ica, phase, amplitude, correlation, light, eeg, linear, processing</td>\n",
       "      <td>Extended ICA Removes Artifacts from \\nElectroencephalographic Recordings \\nTzyy-Ping Jung , Colin Humphries , Te-Won Lee , Scott Makeig 2'3, \\nMartin J. McKeown , Vicente Iragui 3, Terrence J....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1276</td>\n",
       "      <td>8</td>\n",
       "      <td>46.83</td>\n",
       "      <td>prediction, application, experiment, table, user, query, time_series, variable, sequence, type, block, predictor, modeling, future, technique, predictive, predict, series, predicted, protein</td>\n",
       "      <td>Predicting Lifetimes in Dynamically \\nAllocated Memory \\nDavid A. Cohn \\nAdaptive Systems Group \\nHarlequin, Inc. \\nMenlo Park, CA 94025 \\ncohnharlequin. tom \\nSatinder Singh \\nDepartment of Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>168</td>\n",
       "      <td>9</td>\n",
       "      <td>64.30</td>\n",
       "      <td>dynamic, state, memory, pattern, equation, neuron, attractor, capacity, fixed_point, noise, phase, hopfield, teacher, theory, stable, student, matrix, delay, symmetric, behavior</td>\n",
       "      <td>568 \\nDYNAMICS OF ANALOG NEURAL \\nNETWORKS WITH TIME DELAY \\nC.M. Marcus and R.M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge Massachusetts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>938</td>\n",
       "      <td>10</td>\n",
       "      <td>68.41</td>\n",
       "      <td>cell, response, stimulus, activity, visual, receptive_field, map, pattern, spatial, unit, orientation, cortical, layer, cortex, center, region, contrast, eye, area, neuron</td>\n",
       "      <td>Ocular Dominance and Patterned Lateral \\nConnections in a Self-Organizing Model of the \\nPrimary Visual Cortex \\nJoseph Sirosh and Risto Miikkulainen \\nDepartment of Computer Sciences \\nUniversity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1315</td>\n",
       "      <td>11</td>\n",
       "      <td>57.10</td>\n",
       "      <td>distribution, probability, prior, variable, gaussian, bayesian, log, density, approximation, entropy, posterior, probabilistic, likelihood, sample, stochastic, mean_field, hidden, evidence, exp, p...</td>\n",
       "      <td>Approximating Posterior Distributions \\nin Belief Networks using Mixtures \\nChristopher M. Bishop \\nNeil Lawrence \\nNeural Computing Research Group \\nDept. Computer Science &amp; Applied Mathematics \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1403</td>\n",
       "      <td>12</td>\n",
       "      <td>41.85</td>\n",
       "      <td>vector, matrix, distance, component, code, transformation, linear, dimensional, map, dimension, mapping, representation, basis, pca, structure, projection, coding, principal_component, direction, ...</td>\n",
       "      <td>Mapping a manifold of perceptual observations \\nJoshua B. Tenenbaum \\nDepartment of Brain and Cognitive Sciences \\nMassachusetts Institute of Technology, Cambridge, MA 02139 \\nj bt @psyche. mi t. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>242</td>\n",
       "      <td>13</td>\n",
       "      <td>75.64</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, firing, response, synapsis, neural, current, threshold, pattern, et_al, constant, stimulus, oscillator, neuronal, firing_rate, level, effect</td>\n",
       "      <td>18 Harris-Warrick \\nMECHANISMS FOR NEUROMODULATION \\nOF BIOLOGICAL NEURAL NETWORKS \\nRonald M. Harris-Warrick \\nSection of Neurobiology and Behavior \\nCornell University \\nIthaca, NY 14853 \\nABSTR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>652</td>\n",
       "      <td>14</td>\n",
       "      <td>69.10</td>\n",
       "      <td>word, recognition, speech, training, character, sequence, hmm, context, feature, frame, letter, speaker, state, trained, speech_recognition, phoneme, digit, segmentation, mlp, hybrid</td>\n",
       "      <td>Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>855</td>\n",
       "      <td>15</td>\n",
       "      <td>70.54</td>\n",
       "      <td>circuit, chip, current, analog, voltage, neuron, bit, implementation, processor, design, parallel, operation, device, neural, digital, computation, array, synapse, hardware, implemented</td>\n",
       "      <td>Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>791</td>\n",
       "      <td>16</td>\n",
       "      <td>51.99</td>\n",
       "      <td>estimate, estimation, mixture, cluster, regression, variance, expert, clustering, sample, kernel, step, estimator, gaussian, rbf, noise, estimated, em, linear, density, nonlinear</td>\n",
       "      <td>Supervised learning from incomplete \\ndata via an EM approach \\nZoubin Ghahramani and Michael I. Jordan \\nDepartment of Brain &amp; Cognitive Sciences \\nMassachusetts Institute of Techuology \\nCambrid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>223</td>\n",
       "      <td>17</td>\n",
       "      <td>62.92</td>\n",
       "      <td>unit, layer, training, hidden_unit, net, pattern, architecture, activation, trained, recurrent, back_propagation, connection, task, hidden_layer, module, hidden, backpropagation, learn, simulation...</td>\n",
       "      <td>524 Fahlman and Lebiere \\nThe Cascade-Correlation Learning Architecture \\nScott E. Fahlman and Christian Lebiere \\nSchool of Computer Science \\nCarnegie-Mellon University \\nPittsburgh, PA 15213 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>558</td>\n",
       "      <td>18</td>\n",
       "      <td>78.91</td>\n",
       "      <td>bound, theorem, class, size, threshold, complexity, proof, loss, polynomial, linear, approximation, probability, assume, theory, definition, xi, defined, constant, bounded, define</td>\n",
       "      <td>Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>378</td>\n",
       "      <td>19</td>\n",
       "      <td>72.26</td>\n",
       "      <td>control, motion, position, trajectory, velocity, movement, direction, motor, target, controller, hand, field, dynamic, feedback, forward, robot, change, arm, location, head</td>\n",
       "      <td>Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>574</td>\n",
       "      <td>20</td>\n",
       "      <td>75.90</td>\n",
       "      <td>node, rule, structure, representation, tree, level, graph, symbol, sequence, string, language, connectionist, similarity, represented, part, role, category, note, machine, item</td>\n",
       "      <td>Harmonic Grammars \\nfor Formal Languages \\nPaul Smolensky \\nDepartment of Computer Science \\nInstitute of Cognitive Science \\nUniversity of Colorado \\nBoulder, Colorado 80309-0430 \\nAbstract \\nBas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Document  ...                                                                                                                                                                                                    Paper\n",
       "Dominant Topic            ...                                                                                                                                                                                                         \n",
       "1                    108  ...  297 \\nA NETWORK FOR IMAGE SEGMENTATION \\nUSING COLOR \\nAnya Hurlbert and Tomaso Poggio \\nCenter for Biological Information Processing at Whitaker College \\nDepartment of Brain and Cognitive Scienc...\n",
       "2                   1197  ...  Removing Noise in On-Line Search using \\nAdaptive Batch Sizes \\nGenevieve B. Orr \\nDepartment of Computer Science \\nWillamette University \\n900 State Street \\nSalem, Oregon 97301 \\ngorr)willamett...\n",
       "3                   1158  ...  Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmhe...\n",
       "4                   1039  ...  Boosting Decision Trees \\nHarris Drucker \\nAT&T Bell Laboratories \\nHolmdel, New Jersey 07733 \\nCorinna Cortes \\nAT&T Bell Laboratories \\nMurray Hill, New Jersey 07974 \\nAbstract \\nA new boosting ...\n",
       "5                    583  ...  A Knowledge-Based Model of Geometry Learning \\nGeoffrey Towell \\nSiemens Corporate Research \\n755 College Road East \\nPrinceton, NJ 08540 \\ntoweli @ learning. siemens. com \\nRichard Lehrer \\nEduca...\n",
       "6                   1003  ...  Softassign versus Softmax: Benchmarks \\nin Combinatorial Optimization \\nSteven Gold \\nDepartment of Computer Science \\nYale University \\nNew Haven, CT 06520-8285 \\nAnand Rangarajan \\nDept. of Diag...\n",
       "7                   1314  ...  Extended ICA Removes Artifacts from \\nElectroencephalographic Recordings \\nTzyy-Ping Jung , Colin Humphries , Te-Won Lee , Scott Makeig 2'3, \\nMartin J. McKeown , Vicente Iragui 3, Terrence J....\n",
       "8                   1276  ...  Predicting Lifetimes in Dynamically \\nAllocated Memory \\nDavid A. Cohn \\nAdaptive Systems Group \\nHarlequin, Inc. \\nMenlo Park, CA 94025 \\ncohnharlequin. tom \\nSatinder Singh \\nDepartment of Comp...\n",
       "9                    168  ...  568 \\nDYNAMICS OF ANALOG NEURAL \\nNETWORKS WITH TIME DELAY \\nC.M. Marcus and R.M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge Massachusetts ...\n",
       "10                   938  ...  Ocular Dominance and Patterned Lateral \\nConnections in a Self-Organizing Model of the \\nPrimary Visual Cortex \\nJoseph Sirosh and Risto Miikkulainen \\nDepartment of Computer Sciences \\nUniversity...\n",
       "11                  1315  ...  Approximating Posterior Distributions \\nin Belief Networks using Mixtures \\nChristopher M. Bishop \\nNeil Lawrence \\nNeural Computing Research Group \\nDept. Computer Science & Applied Mathematics \\...\n",
       "12                  1403  ...  Mapping a manifold of perceptual observations \\nJoshua B. Tenenbaum \\nDepartment of Brain and Cognitive Sciences \\nMassachusetts Institute of Technology, Cambridge, MA 02139 \\nj bt @psyche. mi t. ...\n",
       "13                   242  ...  18 Harris-Warrick \\nMECHANISMS FOR NEUROMODULATION \\nOF BIOLOGICAL NEURAL NETWORKS \\nRonald M. Harris-Warrick \\nSection of Neurobiology and Behavior \\nCornell University \\nIthaca, NY 14853 \\nABSTR...\n",
       "14                   652  ...  Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...\n",
       "15                   855  ...  Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...\n",
       "16                   791  ...  Supervised learning from incomplete \\ndata via an EM approach \\nZoubin Ghahramani and Michael I. Jordan \\nDepartment of Brain & Cognitive Sciences \\nMassachusetts Institute of Techuology \\nCambrid...\n",
       "17                   223  ...  524 Fahlman and Lebiere \\nThe Cascade-Correlation Learning Architecture \\nScott E. Fahlman and Christian Lebiere \\nSchool of Computer Science \\nCarnegie-Mellon University \\nPittsburgh, PA 15213 \\n...\n",
       "18                   558  ...  Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...\n",
       "19                   378  ...  Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditor...\n",
       "20                   574  ...  Harmonic Grammars \\nfor Formal Languages \\nPaul Smolensky \\nDepartment of Computer Science \\nInstitute of Cognitive Science \\nUniversity of Colorado \\nBoulder, Colorado 80309-0430 \\nAbstract \\nBas...\n",
       "\n",
       "[20 rows x 5 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: (topic_set.sort_values(by=['Contribution %'], \n",
    "                                                                                         ascending=False)\n",
    "                                                                             .iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I0QF6K53v4zN",
    "outputId": "5533577d-0cf0-4230-8e50-c404c8feffe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[693, 708, 460]"
      ]
     },
     "execution_count": 229,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_paper_patterns = ['Feudal Reinforcement Learning \\nPeter', 'Illumination-Invariant Face Recognition with a', 'Improved Hidden Markov Model Speech Recognition']\n",
    "sample_paper_idxs = [idx for pattern in sample_paper_patterns \n",
    "                            for idx, content in enumerate(papers) \n",
    "                                if pattern in content]\n",
    "sample_paper_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "d7JrXUbsw0bt",
    "outputId": "6c72404e-0d74-4030-dd1c-02dbf372d6fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>14</td>\n",
       "      <td>49.04</td>\n",
       "      <td>word, recognition, speech, training, character, sequence, hmm, context, feature, frame, letter, speaker, state, trained, speech_recognition, phoneme, digit, segmentation, mlp, hybrid</td>\n",
       "      <td>Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>693</td>\n",
       "      <td>3</td>\n",
       "      <td>47.48</td>\n",
       "      <td>state, action, step, policy, control, reinforcement_learning, environment, optimal, task, goal, reward, td, agent, current, machine, transition, cost, reinforcement, rl, update</td>\n",
       "      <td>Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>38.37</td>\n",
       "      <td>image, object, feature, pixel, view, face, region, visual, representation, surface, edge, location, shape, recognition, scale, contour, local, part, scene, vision</td>\n",
       "      <td>Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document  ...                                                                                                                                                                                                    Paper\n",
       "460       460  ...  Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...\n",
       "693       693  ...  Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...\n",
       "708       708  ...  Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...\n",
       "\n",
       "[3 rows x 5 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "(corpus_topic_df[corpus_topic_df['Document']\n",
    "                 .isin(sample_paper_idxs)])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Topic Modeling.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
